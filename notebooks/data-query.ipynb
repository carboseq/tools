{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJP Common template - Data Query Module (v0.6.5)\n",
    "Upload the database and then use tabs to filter the data, make queries and generate different export files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import matplotlib.dates as mdates\n",
    "import tempfile\n",
    "import requests\n",
    "import os\n",
    "#from zipfile import ZipFile\n",
    "from urllib.parse import parse_qs\n",
    "import base64\n",
    "#from upsetplot import UpSet  # graph with interactions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipyleaflet import Map, Marker, Icon\n",
    "\n",
    "from ipywidgets import (FileUpload, Button, Output, Dropdown, RadioButtons,\n",
    "                        SelectMultiple, VBox, HBox, Layout, Checkbox, Label, Text,\n",
    "                       Tab, FloatRangeSlider, Tab, IntText, FloatText)\n",
    "from IPython.display import FileLink, HTML, Markdown\n",
    "\n",
    "sheetNames = [\n",
    "    'experiment', 'reference', 'treatment', 'soil-type', 'tillage', 'crops',\n",
    "    'amendment', 'irrigation', 'pest-weed', 'grazing',\n",
    "    'soil-crop-measurement', 'data-crop', 'data-soil', 'dropDownList']\n",
    "\n",
    "dtypes = {\n",
    "    'Experiment ID': 'string',\n",
    "    'Treatment ID': 'string',\n",
    "    'Reference treatment': 'string',\n",
    "}\n",
    "\n",
    "def tofloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def camelCase(s):\n",
    "    s = s.split()\n",
    "    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n",
    "\n",
    "def underCase(s):\n",
    "    s = s.split()\n",
    "    return '_'.join(i.lower() for i in s)\n",
    "\n",
    "def dicCopy(dic):\n",
    "    bdic = {}\n",
    "    for key in dic:\n",
    "        bdic[key] = dic[key].copy()\n",
    "    return bdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame({\n",
    "#     'Sampling year': [np.nan, np.nan, np.nan],\n",
    "#     'SOC': [0.4, 0.2, 0.1],\n",
    "# })\n",
    "# df2 = pd.DataFrame({\n",
    "#     'Sampling year': [np.nan, np.nan, np.nan],\n",
    "#     'Yield': [1245, 564, 2345]\n",
    "# })\n",
    "# display(df1)\n",
    "# display(df2)\n",
    "# pd.merge(df1, df2, on='Sampling year', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.random.rand(1000, 100))\n",
    "# fname = 'df.csv'\n",
    "# df.to_csv(fname)\n",
    "# FileLink(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of columns\n",
    "dbdic = {\n",
    "    'experiment': {\n",
    "        'Latitude': 'number',\n",
    "        'Longitude': 'number',\n",
    "        'Country': 'choice',\n",
    "        'Land use prior experiment': 'choice',\n",
    "        \n",
    "    },\n",
    "    'reference': {\n",
    "        'Publication type': 'choice',\n",
    "        'Publication first author': 'string',\n",
    "        'Publication year': 'number',\n",
    "        'Publication title': 'string',\n",
    "        'Publication journal': 'string'\n",
    "    },\n",
    "    'soil-type': {\n",
    "        'Top depth of layer': 'number',\n",
    "        'Bottom depth of layer': 'number',\n",
    "        'Clay (< 0.002 mm)': 'number',\n",
    "        'Silt (0.002 - 0.05 mm)': 'number',\n",
    "        'Sand (0.05 - 2 mm)': 'number',\n",
    "        'Gravel (> 2 mm)': 'number',\n",
    "        'Soil texture USDA': 'choice',\n",
    "        'Soil group WRB': 'choice',\n",
    "        'Soil group WRB qualifier': 'choice',\n",
    "        'Soil group WRB specifier': 'choice',\n",
    "        'Soil type USDA': 'choice',\n",
    "        'Soil type USDA qualifier': 'choice',\n",
    "    },\n",
    "    'treatment': {\n",
    "        'Land use': 'choice',\n",
    "        'Year started': 'number',\n",
    "        'Year ended': 'number',\n",
    "        'Crop rotation': 'choice'\n",
    "    },\n",
    "    'tillage': {\n",
    "        'Rotation': 'choice',\n",
    "        'Tillage system': 'choice',\n",
    "        'Tillage method': 'choice',\n",
    "        'Tillage depth': 'number',\n",
    "        'Permanent soil area covered by residues or crops': 'choice',\n",
    "        'Tillage period': 'choice',\n",
    "    },\n",
    "    'crops': {\n",
    "        'Rotation': 'choice',\n",
    "        'Crop type': 'choice',\n",
    "        'Cropping system': 'choice',\n",
    "        'Crop': 'choice',\n",
    "        'Harvesting/Termination method': 'choice',\n",
    "        'Harvesting frequency': 'number',\n",
    "        'Sowing period': 'choice',\n",
    "        'Harvesting/Termination period': 'choice',\n",
    "        'Residues removal': 'choice',\n",
    "        'Residues incorporation': 'choice', \n",
    "        'Residues burning': 'choice'\n",
    "    },\n",
    "    'amendment': {\n",
    "        'Rotation': 'choice',\n",
    "        'Type of fertilizer/amendment': 'choice',\n",
    "        'Fertilizer/Amendment application rate': 'number',\n",
    "        'Fertilizer/Amendment application rate units': 'choice',\n",
    "        'Fertilizer/Amendment application method': 'choice',\n",
    "        'Amendment water content': 'number',\n",
    "        'Amendment C': 'number',\n",
    "        'Amendment N': 'number',\n",
    "        'Amendment P': 'number',\n",
    "        'Amendment K': 'number',\n",
    "    },\n",
    "    'irrigation': {\n",
    "        'Rotation': 'choice',\n",
    "        'Irrigation method': 'choice',\n",
    "        'Amount of water': 'number',\n",
    "        'Irrigation frequency': 'number',\n",
    "        'Irrigation water': 'choice',\n",
    "        'Drainage system': 'choice',\n",
    "        'Drainage spacing': 'number',\n",
    "        'Drainage depth': 'number',\n",
    "    },\n",
    "    'data-crop': {\n",
    "        'Rotation': 'choice',\n",
    "        'Sampling year': 'number',\n",
    "        'Harvested yield': 'number',\n",
    "        'Harvested yield water content': 'choice',\n",
    "        'Harvested yield water content amount': 'number',\n",
    "        'Residue above-ground': 'number',\n",
    "        'Residue stubble': 'number',\n",
    "        'Residue roots': 'number',\n",
    "        'Residue sampling method': 'string',\n",
    "        'Below-ground sampling depth': 'number',\n",
    "    },\n",
    "    'data-soil': {\n",
    "        'Rotation': 'choice',\n",
    "        'Sampling year': 'number',\n",
    "        'Depth from': 'number',\n",
    "        'Depth to': 'number',\n",
    "        'Time-serie available': 'choice',\n",
    "        'SOC conc': 'number',\n",
    "        'SOC conc SD': 'number',\n",
    "        'SOC conc SE': 'number',\n",
    "        'SOC conc nb samples': 'number',\n",
    "        'Analysis method': 'choice',\n",
    "        'Bulk density': 'number',\n",
    "        'Bulk density method': 'choice',\n",
    "        'Bulk density SD': 'number',\n",
    "        'Bulk density SE': 'number',\n",
    "        'Bulk density nb samples': 'number',\n",
    "        'SOC stock': 'number',\n",
    "        'SOC stock SD': 'number',\n",
    "        'SOC stock SE': 'number',\n",
    "        'SOC stock nb samples': 'number',\n",
    "        'pH': 'number',\n",
    "        'pH method': 'choice'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel(fname):\n",
    "    t0 = time.time()\n",
    "    print('Reading in Excel file...', end='')\n",
    "    if fname[:4] == 'http': # it's a google sheet url\n",
    "        fname = '/'.join(fname.split('/')[:-1] + ['export?format=xlsx'])\n",
    "        response = requests.get(fname)\n",
    "        data = response.content\n",
    "    elif isinstance(fname, str):\n",
    "        with open(fname, 'rb') as f:\n",
    "            data = f.read()\n",
    "    else:\n",
    "        data = fname\n",
    "\n",
    "    dfdic = pd.read_excel(data, sheet_name=None, skiprows=[0,1,3])\n",
    "    version = pd.read_excel(data, sheet_name='README', header=None).iloc[0, 2]\n",
    "\n",
    "    # convert potential bool columns to string (for trasks for WP2 for eg)\n",
    "    for sheet in list(dfdic.keys())[2:-1]:\n",
    "        dtypes = dfdic[sheet].dtypes\n",
    "        bcols = dfdic[sheet].columns[dtypes == 'bool']\n",
    "        dfdic[sheet].loc[:, bcols] = dfdic[sheet][bcols].astype(str)\n",
    "\n",
    "    print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "    return dfdic, version\n",
    "\n",
    "#dfdic, version = readExcel('https://docs.google.com/spreadsheets/d/1JA0EttKnzyEUDM0FLxwLMTQA0k0zBdGd/edit')\n",
    "#dfdic, version = readExcel('../../carboseq-wp2-db-levels.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns list of columns with given dtype for specific sheet\n",
    "def getOptions(dfdic, sheet, onlyObject=True, rot=True):\n",
    "    df = dfdic[sheet]\n",
    "    ie = (~(df.columns.str.slice(-3, None) == ' ID')\n",
    "          & ~(df.columns.str.slice(-10, None) == ' (comment)')\n",
    "          & ~(df.columns == 'Treatment definition'))\n",
    "    if onlyObject:\n",
    "        ie = ie & (df.dtypes == 'object')\n",
    "    if rot is False:\n",
    "        ie = ie & (df.columns != 'Rotation')\n",
    "    return df.columns[ie].tolist()\n",
    "\n",
    "#getOptions(dfdic, 'crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show map of experiments\n",
    "def showMap(dfdic):\n",
    "    # interactive map\n",
    "    m = Map(\n",
    "        center=(52.204793, 360.121558),\n",
    "        zoom=4\n",
    "    )\n",
    "    df = dfdic['experiment']\n",
    "    for i in range(df.shape[0]):\n",
    "        lat, lon = df.loc[i, 'Latitude'], df.loc[i, 'Longitude']\n",
    "        marker = Marker(location=(lat, 360+lon),\n",
    "                        title=str(df.loc[i, 'Experiment ID']),\n",
    "                        #icon=Icon(color='blue', icon='circle', prefix='fa'),\n",
    "                        draggable=False)\n",
    "        m.add_layer(marker)\n",
    "    display(m)\n",
    "#showMap(dfdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter experiments\n",
    "class RowFilter(object):\n",
    "    def __init__(self, filters, dfdic):\n",
    "        self.sheetDropdown = Dropdown(options=list(dbdic.keys()), layout=Layout(width='15%'))\n",
    "        self.sheetDropdown.observe(self.sheetDropdownFunc, names='value')\n",
    "        self.colDropdown = Dropdown(options=getOptions(dfdic, 'experiment', False), layout=Layout(width='15%'))\n",
    "        self.colDropdown.observe(self.colDropdownFunc, names='value')\n",
    "        self.rmBtn = Button(description='Remove')\n",
    "        self.rmBtn.on_click(self.rmBtnFunc)\n",
    "        self.hbox = HBox([self.sheetDropdown, self.colDropdown, self.rmBtn], layout=Layout(display='flex'))\n",
    "        self.filters = filters\n",
    "        self.index = len(self.filters.children) - 1\n",
    "        self.filters.children = self.filters.children[:-1] + (self.hbox, self.filters.children[-1])\n",
    "        self.dfdic = dfdic\n",
    "        self.opts = None\n",
    "        self.buildOptions('experiment', 'Latitude')\n",
    "        self.colDropdown.value = 'Latitude'\n",
    "\n",
    "    def sheetDropdownFunc(self, a):\n",
    "        self.colDropdown.options = getOptions(self.dfdic, a['new'])\n",
    "\n",
    "    def colDropdownFunc(self, a):\n",
    "        sheet = self.sheetDropdown.value\n",
    "        col = a['new']\n",
    "        self.buildOptions(sheet, col)\n",
    "\n",
    "    def buildOptions(self, sheet, col):\n",
    "        typ = self.dfdic[sheet][col].dtype\n",
    "        if typ != 'object' and typ != 'bool':\n",
    "            vmin = self.dfdic[sheet][col].min()\n",
    "            vmax = self.dfdic[sheet][col].max()\n",
    "            r = vmax - vmin\n",
    "            #opts = FloatRangeSlider(value=[vmin, vmax], vmin=vmin - 0.1*r, vmax=vmax + 0.1*r, step=0.02*r)\n",
    "            self.opts = HBox([Label('min:'), FloatText(value=vmin, layout=Layout(width='30%')),\n",
    "                              Label('max:'), FloatText(value=vmax, layout=Layout(width='30%'))])\n",
    "        else:\n",
    "            choices = self.dfdic[sheet][col].dropna().unique()\n",
    "            checkboxes = [Checkbox(value=True, description=a, indent=False)\n",
    "                                  for a in choices]\n",
    "            def checkallFunc(a):\n",
    "                for c in checkboxes:\n",
    "                    c.value = a['new']\n",
    "            checkall = Checkbox(value=True, description='Select all', indent=False)\n",
    "            checkall.observe(checkallFunc, names='value')\n",
    "            self.opts = VBox([checkall] + checkboxes, layout=Layout(width='40%'))\n",
    "\n",
    "        if len(self.hbox.children) > 3:\n",
    "            self.hbox.children = self.hbox.children[:-2] + (self.opts, self.hbox.children[-1])\n",
    "        else:\n",
    "            self.hbox.children = self.hbox.children[:-1] + (self.opts, self.hbox.children[-1])\n",
    "\n",
    "    def rmBtnFunc(self, a):\n",
    "        b = list(self.filters.children)\n",
    "        del b[self.index]\n",
    "        self.filters.children = b\n",
    "\n",
    "def buildFilters():\n",
    "    global dfdic, dfdico, out\n",
    "\n",
    "    filterLog = Output()\n",
    "    #with log:\n",
    "    #    print('Note: click \"Reset filters\" to restore the initial database.')\n",
    "\n",
    "    def addFilterBtnFunc(b):\n",
    "        _ = RowFilter(filters, dfdic)\n",
    "    addFilterBtn = Button(description='Add filter')\n",
    "    addFilterBtn.on_click(addFilterBtnFunc)\n",
    "\n",
    "    def filterDataBtnFunc(a):\n",
    "        global dfdic, dfdico, expOut\n",
    "        expOut.clear_output() # also clear exports\n",
    "        dfdic = dicCopy(dfdico)  # always start from the original database\n",
    "        expids = pd.Series(dfdic['experiment']['Experiment ID'].unique())\n",
    "        nexp = len(expids)\n",
    "        for child in filters.children[:-1]:\n",
    "            sheet = child.children[0].value\n",
    "            col = child.children[1].value\n",
    "            typ = dfdic[sheet][col].dtype\n",
    "            if typ != 'object':\n",
    "                vmin = child.children[2].children[1].value\n",
    "                vmax = child.children[2].children[3].value\n",
    "                ie = (dfdic[sheet][col] >= vmin) & (dfdic[sheet][col] <= vmax)\n",
    "            else:\n",
    "                choices = [b.description for b in child.children[2].children[1:] if b.value is True]\n",
    "                # exclude first child as it's the 'select all' checkbox\n",
    "                ie = dfdic[sheet][col].isin(choices)\n",
    "            expids = expids[expids.isin(dfdic[sheet][ie]['Experiment ID'].unique())]\n",
    "\n",
    "        # do the filtering\n",
    "        expids = expids.tolist()\n",
    "        for sheet in dfdic.keys():\n",
    "            if 'Experiment ID' in dfdic[sheet].keys():\n",
    "                ie = dfdic[sheet]['Experiment ID'].isin(expids)\n",
    "                dfdic[sheet] = dfdic[sheet][ie].reset_index(drop=True)\n",
    "\n",
    "        filterLog.clear_output()\n",
    "        with filterLog:\n",
    "            print('Experiment ID retained: {:d}/{:d}'.format(len(expids), nexp))\n",
    "            showMap(dfdic)  # cannot update map in tab1 as it's not visible (so all tiles don't load)\n",
    "            # but in the current tab it is possible\n",
    "        \n",
    "    filterDataBtn = Button(description='Apply filters')\n",
    "    filterDataBtn.on_click(filterDataBtnFunc)\n",
    "\n",
    "    def resetFilterBtnFunc(a):\n",
    "        # we want to restore the global dfdic variable\n",
    "        filters.children = (filters.children[-1],)\n",
    "        filterDataBtnFunc(42)\n",
    "    resetFilterBtn = Button(description='Reset filters')\n",
    "    resetFilterBtn.on_click(resetFilterBtnFunc)\n",
    "    \n",
    "\n",
    "    filters = VBox([VBox([HBox([addFilterBtn, filterDataBtn, resetFilterBtn]), filterLog])])\n",
    "    return filters\n",
    "\n",
    "# filters = buildFilters()\n",
    "# filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive histogram view\n",
    "# class ExploratoryHist(object):\n",
    "#     def __init__(self, dfdic):\n",
    "#         self.sheetDropdown = Dropdown(options=list(dbdic.keys()), layout=Layout(width='25%'))\n",
    "#         self.sheetDropdown.observe(self.sheetDropdownFunc, names='value')\n",
    "#         self.colDropdown = Dropdown(options=list(dbdic['experiment'].keys()), layout=Layout(width='35%'))\n",
    "#         self.colDropdown.observe(self.colDropdownFunc, names='value')\n",
    "#         self.vminText = FloatText(layout=Layout(width='15%'))\n",
    "#         self.vmaxText = FloatText(layout=Layout(width='15%'))\n",
    "#         self.nbins = IntText(layout=Layout(width='10%'))\n",
    "#         self.dfdic = dfdic\n",
    "#         self.showLog = Checkbox(value=True, description='Show values head/tail', indent=False)\n",
    "#         self.out = Output()\n",
    "#         self.log = Output()\n",
    "#         self.header = HBox([self.sheetDropdown, self.colDropdown])\n",
    "#         self.numberOption = HBox([Label('Vmin:'), self.vminText,\n",
    "#                                   Label('Vmax:'), self.vmaxText,\n",
    "#                                   Label('Nb. bins:'), self.nbins])\n",
    "#         self.hbox = HBox([VBox([self.header, self.out], layout=Layout(width='60%')),\n",
    "#                           VBox([self.showLog, self.log])])\n",
    "#         self.bins = None\n",
    "#         self.sheet = 'experiment'\n",
    "#         self.col = 'Latitude'\n",
    "#         self.colDropdownFunc({'new': 'Latitude'})\n",
    "#         #self.buildFigure('experiment', 'Latitude')\n",
    "\n",
    "#     def sheetDropdownFunc(self, a):\n",
    "#         self.sheet = a['new']\n",
    "#         self.colDropdown.options = list(dbdic[a['new']].keys())\n",
    "\n",
    "#     def colDropdownFunc(self, a):\n",
    "#         self.col = a['new']\n",
    "#         typ = dbdic[self.sheet][self.col]\n",
    "#         if typ == 'number':\n",
    "#             self.vminText.unobserve_all()\n",
    "#             self.vmaxText.unobserve_all()\n",
    "#             self.nbins.unobserve_all()\n",
    "#             _, bins = np.histogram(self.dfdic[self.sheet][self.col].dropna())\n",
    "#             self.vminText.value = np.round(bins[0], 2)\n",
    "#             self.vmaxText.value = np.round(bins[-1], 2)\n",
    "#             self.nbins.value = len(bins)\n",
    "#             self.vminText.observe(self.updateFunc, names='value')\n",
    "#             self.vmaxText.observe(self.updateFunc, names='value')\n",
    "#             self.nbins.observe(self.updateFunc, names='value')\n",
    "#             self.bins = bins\n",
    "#             self.hbox.children[0].children = (self.header, self.numberOption, self.out)\n",
    "#             self.buildFigure()\n",
    "#         else:\n",
    "#             self.hbox.children[0].children = (self.header, self.out)\n",
    "#             self.buildFigure()\n",
    "\n",
    "#     def updateFunc(self, a):\n",
    "#         vmin = self.vminText.value\n",
    "#         vmax = self.vmaxText.value\n",
    "#         nbins = self.nbins.value\n",
    "#         self.bins = np.linspace(vmin, vmax, nbins)\n",
    "#         self.buildFigure()\n",
    "\n",
    "#     def buildFigure(self):\n",
    "#         self.out.clear_output()\n",
    "#         self.log.clear_output()\n",
    "#         with self.log:\n",
    "#             if self.showLog.value is True:\n",
    "#                 if self.dfdic[self.sheet].shape[0] > 10:\n",
    "#                     print(self.dfdic[self.sheet].sort_values(self.col).reset_index().iloc[np.r_[0:5, -5:0]][self.col])\n",
    "#                 else:\n",
    "#                     print(self.dfdic[self.sheet][self.col].sort_values(self.col).reset_index())\n",
    "#         with self.out:\n",
    "#             typ = dbdic[self.sheet][self.col]\n",
    "#             if typ == 'number':\n",
    "#                 self.dfdic[self.sheet][self.col].apply(tofloat).plot.hist(bins=self.bins)\n",
    "#                 plt.xlabel(self.col)\n",
    "#             else:\n",
    "#                 self.dfdic[self.sheet][self.col].value_counts().plot(kind='bar', xlabel=self.col)\n",
    "#                 plt.ylabel('Count')\n",
    "#             plt.show() # needed, otherwise, graph won't change\n",
    "\n",
    "#expHist = ExploratoryHist(dfdic)\n",
    "#display(expHist.hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract treatments (advanced)\n",
    "# Pairwise strategy:\n",
    "# - filters: conditions to be applied (list of choices to keep or range of numerical values to keep)\n",
    "# - inclusion of 'Rotation' in conditions or not:\n",
    "#     - inclusion: comparison will be done if all the year in the rotation met the conditions\n",
    "#     - not included: comparison will be done if at least one year in the rotation met the conditions\n",
    "# - value: choice or boolean rules if numeric values\n",
    "# - occurence (of a value):\n",
    "#     - -1: neglect this parameter and compare the value vs other values\n",
    "#     - 0: compare the 0 occurence vs > 0 occurence (at lest one occurence)\n",
    "#     - 1: compare the 1 occurence vs > 1 occurence (hence neglecting the 0 occurence)\n",
    "# - conditions:\n",
    "#     - column name and value: only the row with where this column has this value will be considered in the comparison\n",
    "#     - column name and 'identical': comparison between two rows will only be considered if the value in this column are the same between the two rows compared\n",
    "\n",
    "queries = {\n",
    "    'different tillage': {\n",
    "        'sheet': 'tillage',\n",
    "        'column': 'Tillage system',\n",
    "        'value': 'Zero tillage',\n",
    "        'occurence': -1,\n",
    "        'conditions': [('crops', 'Cropping system', None)],\n",
    "    },\n",
    "    'cover crop vs no cover crops': {\n",
    "        'sheet': 'crops',\n",
    "        'column': 'Crop type',\n",
    "        'value': 'Cover crop',\n",
    "        'occurence': 0,\n",
    "        'conditions': [('crops', 'Cropping system', None),\n",
    "                       ('tillage', 'Tillage system', None)],\n",
    "    },\n",
    "    'one main crop vs double cropping': {\n",
    "        'sheet': 'crops',\n",
    "        'column': 'Crop type',\n",
    "        'value': 'Main crop',\n",
    "        'occurence': 1,\n",
    "        'conditions': [('crops', 'Cropping system', 'Monoculture'),\n",
    "                       ('crops', 'Rotation', None)]\n",
    "    },\n",
    "    # 'cover crop X vs cover crops Y': {\n",
    "    #     'sheet': 'crops',\n",
    "    #     'column': 'Crop',\n",
    "    #     'value': '>> Clover/Trifolium sp.',\n",
    "    #     'occurence': -1,\n",
    "    #     'conditions': [('crops', 'Crop type', 'Cover crop'),\n",
    "    #                    ('crops', 'Rotation', None)]\n",
    "    # },\n",
    "    # 'different termination method': {\n",
    "    #     'sheet': 'crops',\n",
    "    #     'column': 'Harvesting/Termination method',\n",
    "    #     'value': '> Frost-killed',\n",
    "    #     'occurence': -1,\n",
    "    #     'conditions': [('crops', 'Crop type', 'Cover crop')]\n",
    "    # },\n",
    "    # 'different growing period': {\n",
    "    #     'sheet': 'crops',\n",
    "    #     'column': 'Sowing period',\n",
    "    #     'value': 'March',\n",
    "    #     'occurence': -1,\n",
    "    #     'conditions': [('crops', 'Crop type', 'Cover crop')]\n",
    "    # },\n",
    "    'residues incorporated vs residue left on surface': {\n",
    "        'sheet': 'crops',\n",
    "        'column': 'Residues removal',\n",
    "        'value': 'Full residue removal',\n",
    "        'occurence': -1,\n",
    "        'conditions': [('crops', 'Crop', None),\n",
    "                       ('crops', 'Crop type', 'Main crop')]\n",
    "    }\n",
    "}\n",
    "\n",
    "def extractQueries(queries, dfdic, debug=False):\n",
    "    # create dataframe to store the pairwise comparison\n",
    "    compdict = {}\n",
    "    def dump(*args):\n",
    "        if debug:\n",
    "            print(*args)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    for key in tqdm(queries):\n",
    "        # define query\n",
    "        query = queries[key]\n",
    "        compdict[key] = []\n",
    "\n",
    "        # extract the conditions on values and build filtered df for tab\n",
    "        df = dfdic[query['sheet']]\n",
    "        i2keep = np.ones(df.shape[0], dtype=bool)\n",
    "        sameCols = []  # list of column that must be similar between pairwise\n",
    "        crossCols = []  # list of column similar but in other sheets\n",
    "        for row in query['conditions']:\n",
    "            if row[0] == query['sheet']:\n",
    "                val = row[2]\n",
    "                if val is None:\n",
    "                    sameCols.append(row[1])\n",
    "                else:\n",
    "                    i2keep = i2keep & df[row[1]].eq(val)\n",
    "            else:\n",
    "                crossCols.append((row[0], row[1]))\n",
    "        df = df[i2keep].reset_index(drop=True)\n",
    "        dfcross = pd.DataFrame(crossCols, columns=['sheet', 'column'])\n",
    "\n",
    "        # add Rotation year if not in df (to make the code more flexible)\n",
    "        if 'Rotation' not in df.columns:\n",
    "            df['Rotation'] = 'year0'\n",
    "\n",
    "        # columns to use for pairwise comparison\n",
    "        col = query['column']\n",
    "        cols = [col] + sameCols\n",
    "\n",
    "        # cannot compare number 1 vs multiple accross rotation but only inside\n",
    "        if (query['occurence'] >= 1) & ('Rotation' not in cols):\n",
    "            cols.append('Rotation')\n",
    "            print('WARNING: cannot compare number 1 vs multiple accross rotation but only inside rotation')\n",
    "\n",
    "        # identify rows which are equal to query value\n",
    "        iref = df[col] == query['value']\n",
    "\n",
    "        # repeat for each experiment in the tab\n",
    "        expids = df['Experiment ID'].unique()\n",
    "        for expid in tqdm(expids):\n",
    "            ie = df['Experiment ID'] == expid\n",
    "            treatids = df[ie]['Treatment ID'].unique()\n",
    "            dump('||| expid: ' + str(expid) + ' with {:d} treatids'.format(len(treatids)))\n",
    "\n",
    "            # only investigate expid where the query value is present\n",
    "            if (ie & iref).sum() > 0:\n",
    "\n",
    "                # first loop looks for the reference/control treatment\n",
    "                for i, treatid1 in enumerate(treatids):\n",
    "                    itreat1 = ie & df['Treatment ID'].eq(treatid1)\n",
    "\n",
    "                    # get the potential rows which contain the control values\n",
    "                    icontrol = itreat1 & iref\n",
    "                    \n",
    "                    controlFound = False\n",
    "                    # if there is at least one occurence value vs other value)\n",
    "                    if query['occurence'] < 0:\n",
    "                        if np.sum(icontrol) > 0:\n",
    "                            controlFound = True\n",
    "\n",
    "                    # if there is presence or absence\n",
    "                    elif query['occurence'] == 0:\n",
    "                        #print('occ0', treatid1, irows, end='')\n",
    "                        # for this to be a control, none of the rows should contain the value\n",
    "                        if np.sum(icontrol) == 0:\n",
    "                            controlFound = True\n",
    "\n",
    "                    # if there is the exact number of occurence specified (within a rotation)\n",
    "                    else:\n",
    "                        # compute number of occurence of the control within a rotation year\n",
    "                        icounts = df[icontrol].groupby('Rotation').count()\n",
    "                        if query['occurence'] in icounts.loc[:, icounts.columns[0]].to_list():\n",
    "                            controlFound = True\n",
    "\n",
    "                    if controlFound:\n",
    "                        dump('\\tcontrol found ({:s}) with value:'.format(str(treatid1)),\n",
    "                            df[itreat1][cols].values.tolist())\n",
    "\n",
    "                        # once reference is found,look for the corresponding treatments\n",
    "                        for j, treatid2 in enumerate(treatids):\n",
    "                            itreat2 = ie & df['Treatment ID'].eq(treatid2)\n",
    "\n",
    "                            # don't look into the same treatment already selected as control (j != i)\n",
    "                            # don't look into treatment if it contains NaN for the column of interest\n",
    "                            # don't look into treatment if it does not contain the value (occurence = 0)\n",
    "                            if ((j != i) \n",
    "                                & (df[itreat2][col].isna().sum() == 0)\n",
    "                                & (\n",
    "                                    ( # if we look for the presence, the treatid2 must have at least one of this value\n",
    "                                        (query['occurence'] == 0) \n",
    "                                         & (df[itreat2][col].eq(query['value']).sum() > 0))\n",
    "                                    | ( # if we look for multiple occurence of value, check treatid2 has them\n",
    "                                        (query['occurence'] > 0)\n",
    "                                        & (df[itreat2][col].eq(query['value']).sum() > query['occurence']))\n",
    "                                    # if we look for this value vs other, then we take them all as their place in the\n",
    "                                    # rotation will matter\n",
    "                                    | (query['occurence'] < 0))\n",
    "                               ):\n",
    "\n",
    "                                # check if treat2 satisfy the crossCols conditions (same columns in different sheets)\n",
    "                                condCross = True\n",
    "                                for csheet in dfcross['sheet'].unique():\n",
    "                                    ic = dfcross['sheet'] == csheet\n",
    "                                    scols = dfcross[ic]['column'].tolist()\n",
    "                                    cdf = dfdic[csheet]\n",
    "                                    df1 = cdf[cdf['Experiment ID'].eq(expid) &\n",
    "                                            cdf['Treatment ID'].eq(treatid1)].reset_index(drop=True)\n",
    "                                    df2 = cdf[cdf['Experiment ID'].eq(expid) &\n",
    "                                            cdf['Treatment ID'].eq(treatid2)].reset_index(drop=True)\n",
    "                                    if condCross is True:\n",
    "                                        # if both trt and ctrl have same size (maybe both empty)\n",
    "                                        if (df1.shape[0] > 0) & (df2.shape[0] > 0):\n",
    "                                            for l in range(df1.shape[0]):\n",
    "                                                #print('==', scols, '\\n', df2[scols].eq(df1.loc[l, scols]), df2[scols].eq(df1.loc[l, scols]).all(1).any(0))\n",
    "                                                if df2[scols].eq(df1.loc[l, scols]).all(1).any(0) == True:\n",
    "                                                    #print('+/', df2[scols].eq(df1.loc[l, scols]).all(1).any(0))\n",
    "                                                    # there is at least one row which is identical between ctrl and trt\n",
    "                                                    pass\n",
    "                                                else:\n",
    "                                                    condCross = False\n",
    "                                                    break\n",
    "                                        elif (df1.shape[0] == 0) & (df2.shape[0] == 0):\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            condCross = False\n",
    "                                            break\n",
    "\n",
    "                                if condCross is True:\n",
    "                                    dump('\\t\\tpassed conditions: ' + treatid1 + ' >> << ' + treatid2)\n",
    "\n",
    "                                    # wether to do the comparison for each rotation or not\n",
    "                                    ftreat = False\n",
    "\n",
    "                                    # one value VS all other values\n",
    "                                    if query['occurence'] == -1:\n",
    "                                        subdf2 = df[itreat2][cols]\n",
    "                                        for irow in np.where(icontrol)[0]:\n",
    "                                            match = subdf2.eq(df.loc[irow, cols])\n",
    "\n",
    "                                            # only row different from the control values are wanted\n",
    "                                            match[col] = ~match[col]\n",
    "                                            # all rows with difference value than the control but same columns ok\n",
    "                                            if match.all(1).any(0):\n",
    "                                                ftreat = True\n",
    "                                                #print('=== value vs other value', expid, treatid1, treatid2)\n",
    "                                                compdict[key].append([expid, treatid1, treatid2])\n",
    "                                                break  # no need to test the other rows\n",
    "\n",
    "                                    # absence VS presence of the value (absence is the control)\n",
    "                                    elif query['occurence'] == 0:\n",
    "                                        subdf2 = df[itreat2][cols]\n",
    "                                        for irow in df[df['Treatment ID'] == treatid1].index.to_list():\n",
    "                                            match = subdf2.eq(df.loc[irow, cols])\n",
    "\n",
    "                                            # among the rows with sameCols ok, check if at least a different row with\n",
    "                                            # the query value compared to control value\n",
    "                                            isub = match[sameCols].all(1) & subdf2[col].eq(query['value'])\n",
    "                                            if (isub.sum() > 0):\n",
    "                                                ftreat = True\n",
    "                                                dump('=== presence vs absence', expid, treatid1, treatid2)\n",
    "                                                compdict[key].append([expid, treatid1, treatid2])\n",
    "                                                break\n",
    "\n",
    "                                    # 1 occurences VS more than 1 occurence of the value\n",
    "                                    # ISSUE cannot compare 2 VS more than 2 because colSames comparison will be difficult\n",
    "                                    # as it's an edge case, we keep comparing 1 occurence vs more than 1\n",
    "                                    else:\n",
    "                                        subdf2 = df[itreat2][cols]\n",
    "                                        for rotid in subdf2['Rotation'].unique():\n",
    "                                            irowCtrl = df[itreat1 & df['Rotation'].eq(rotid)][col].eq(query['value'])\n",
    "                                            irot = subdf2['Rotation'].eq(rotid)\n",
    "                                            irowTrt = subdf2[col].eq(query['value']) & irot\n",
    "                                            if irowCtrl.sum() == query['occurence']:\n",
    "                                                # trick, here we only compare the first line so we assume the occurence == 1 for control\n",
    "                                                match = subdf2[irowTrt].eq(df.loc[np.where(irowCtrl)[0][0], cols])\n",
    "\n",
    "                                                # check number of occurence in itreat2\n",
    "                                                if match.all(1).sum() > query['occurence']:\n",
    "                                                    ftreat = True\n",
    "                                                    compdict[key].append([expid, treatid1, treatid2])\n",
    "                                                    #print('=== one vs more occurence', expid, treatid1, treatid2)\n",
    "                                                    break\n",
    "\n",
    "    # convert list of list to pandas.DataFrame\n",
    "    for key in compdict:\n",
    "        compdict[key] = pd.DataFrame(compdict[key], columns=['expid', 'treatid_C', 'treatid_T'])\n",
    "\n",
    "    return compdict\n",
    "\n",
    "\n",
    "\n",
    "# ISSUE: you can have \"at least one occurence\" inside the rotation OR inside the treatment\n",
    "\n",
    "#compdict = extractQueries(queries, dfdic)\n",
    "# for key in compdict:\n",
    "#     print(key, ':')\n",
    "#     display(compdict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive query building (UI)\n",
    "# this module add a row for each query where you can defined the control values, occurence\n",
    "# and add additional conditions from the same tab or not\n",
    "# getQueries enables to extract the information from the UI into a dictionnary of queries\n",
    "\n",
    "# class to add condition (within the same table)\n",
    "class RowCondition(object):\n",
    "    def __init__(self, rows, sheet, dfdic):\n",
    "        #options = [b for b in dbdic[sheet] if dbdic[sheet][b] == 'choice']\n",
    "        #options = ['Rotation'] + options if 'Rotation' in dfdic[sheet].columns else options\n",
    "        options = getOptions(dfdic, sheet)\n",
    "        self.sheetDropdown = Dropdown(options=list(dbdic.keys())[3:-2], layout=Layout(width='25%'))\n",
    "        self.sheetDropdown.value = sheet\n",
    "        self.sheetDropdown.observe(self.sheetDropdownFunc, names='value')\n",
    "        self.colDropdown = Dropdown(options=options, layout=Layout(width='25%'))\n",
    "        self.colDropdown.observe(self.colDropdownFunc, names='value')\n",
    "        self.valDropdown = Dropdown(layout=Layout(width='30%'))\n",
    "        self.rmBtn = Button(description='Remove')\n",
    "        self.rmBtn.on_click(self.rmBtnFunc)\n",
    "        self.hbox = HBox([Label('Sheet:', layout=Layout(width='50px')), self.sheetDropdown,\n",
    "                          Label('Col:', layout=Layout(width='30px')), self.colDropdown,\n",
    "                          Label('Val:', layout=Layout(width='30px')), self.valDropdown, self.rmBtn])\n",
    "        self.rows = rows\n",
    "        self.sheet = sheet\n",
    "        self.dfdic = dfdic\n",
    "        self.rows.children = self.rows.children + (self.hbox, )\n",
    "        self.index = len(self.rows.children) - 1\n",
    "        self.colDropdownFunc({'new': options[0]})\n",
    "\n",
    "    def sheetDropdownFunc(self, a):\n",
    "        newSheet = a['new']\n",
    "        self.colDropdown.options = getOptions(self.dfdic, a['new'])\n",
    "\n",
    "    def colDropdownFunc(self, a):\n",
    "        col = a['new']\n",
    "        if self.sheetDropdown.value == self.sheet:\n",
    "            vals = dfdic[self.sheet][col].dropna().unique()\n",
    "            self.valDropdown.options = ['*Ctrl same as Trt*'] + list(vals)\n",
    "        else:\n",
    "            self.valDropdown.options = ['*Ctrl same as Trt*']\n",
    "\n",
    "    def rmBtnFunc(self, a):\n",
    "        for i, child in enumerate(self.rows.children):\n",
    "            if ((child.children[0].value == self.hbox.children[0].value)\n",
    "                & (child.children[1].value == self.hbox.children[1].value)):\n",
    "                b = list(self.rows.children)\n",
    "                del b[i]\n",
    "                self.rows.children = b\n",
    "                break\n",
    "\n",
    "\n",
    "# class to add reference/control and define occurence and value\n",
    "class RowReference(object):\n",
    "    def __init__(self, rows, dfdic, name=''):\n",
    "        self.sheetDropdown = Dropdown(options=list(dbdic.keys())[3:-2], layout=Layout(width='15%'))\n",
    "        self.sheetDropdown.observe(self.sheetDropdownFunc, names='value')\n",
    "        self.colDropdown = Dropdown(options=[], layout=Layout(width='15%'))\n",
    "        self.colDropdown.observe(self.colDropdownFunc, names='value')\n",
    "        self.refDropdown = Dropdown(options=[], layout=Layout(width='15%'))\n",
    "        self.occurenceDropdown = Dropdown(options=['this value VS other',\n",
    "                                           'absence vs presence of value',\n",
    "                                           '1 occurence vs more'], layout=Layout(width='15%'))\n",
    "        self.rmBtn = Button(description='Remove')\n",
    "        self.rmBtn.on_click(self.rmBtnFunc)\n",
    "        self.hbox = HBox([Label('Sheet:'), self.sheetDropdown,\n",
    "                         Label('Column:'), self.colDropdown,\n",
    "                         Label('Control:'), self.refDropdown,\n",
    "                         Label('Occurence:'), self.occurenceDropdown, self.rmBtn],\n",
    "                         layout=Layout(display='flex'))\n",
    "        self.rows = rows\n",
    "        self.index = len(self.rows.children) - 1\n",
    "        self.conditions = VBox([])\n",
    "        self.addBtn = Button(description='Add condition')\n",
    "        self.addBtn.on_click(self.addBtnFunc)\n",
    "        self.vbox = VBox([Label(name), self.hbox, HBox([\n",
    "            VBox([Label('Conditions:'), self.addBtn]),\n",
    "            self.conditions], layout=Layout(width='90%'))])\n",
    "        self.rows.children = self.rows.children[:-1] + (self.vbox, self.rows.children[-1])\n",
    "        self.dfdic = dfdic\n",
    "        self.opts = None\n",
    "\n",
    "        # initiate initial configuration\n",
    "        self.sheetDropdownFunc({'new': 'treatment'})\n",
    "        self.buildOptions('treatment', 'Land use')\n",
    "        self.colDropdown.value = 'Land use'\n",
    "\n",
    "    def addBtnFunc(self, a):\n",
    "        RowCondition(self.conditions, self.sheetDropdown.value, self.dfdic)\n",
    "\n",
    "    def sheetDropdownFunc(self, a):\n",
    "        sheet = a['new']\n",
    "        self.colDropdown.options = getOptions(self.dfdic, a['new'], rot=False)\n",
    "        self.conditions.children = []\n",
    "\n",
    "    def colDropdownFunc(self, a):\n",
    "        sheet = self.sheetDropdown.value\n",
    "        col = a['new']\n",
    "        self.buildOptions(sheet, col)\n",
    "\n",
    "    def buildOptions(self, sheet, col):\n",
    "        choices = dfdic[sheet][col].dropna().unique()\n",
    "        self.refDropdown.options = choices\n",
    "\n",
    "    def rmBtnFunc(self, _):\n",
    "        for i, child in enumerate(self.rows.children):\n",
    "            if child.children[0].value == self.vbox.children[0].value:\n",
    "                b = list(self.rows.children)\n",
    "                del b[i]\n",
    "                self.rows.children = b\n",
    "                break\n",
    "\n",
    "\n",
    "nameCounter = 0  # to give numerical name to query\n",
    "\n",
    "# add a query row (with a reference and some conditions rows eventually)\n",
    "def buildMetaRef(dfdic):\n",
    "    def addRefBtnFunc(b):\n",
    "        global nameCounter\n",
    "        name = 'query' + str(nameCounter) + ':'\n",
    "        nameCounter += 1\n",
    "        rowRef = RowReference(refs, dfdic, name=name)\n",
    "    addRefBtn = Button(description='Add reference')\n",
    "    addRefBtn.on_click(addRefBtnFunc)\n",
    "    refs = VBox([HBox([addRefBtn])])\n",
    "    return refs\n",
    "\n",
    "\n",
    "# get all values from the UI and form a dictionnary of queries for\n",
    "# extractQueries function\n",
    "def getQueries(refs):\n",
    "    dic = {}\n",
    "    for i, row in enumerate(refs.children[:-1]):\n",
    "        query = row.children[1]\n",
    "        name = row.children[0].value[:-1]\n",
    "        sheet = query.children[1].value\n",
    "        column = query.children[3].value\n",
    "        value = query.children[5].value\n",
    "        occdic = {'this value VS other': -1,\n",
    "                  'absence vs presence of value': 0,\n",
    "                  '1 occurence vs more': 1}\n",
    "        occurence = occdic[query.children[7].value]\n",
    "        conditions = []\n",
    "        for child in row.children[2].children[1].children:\n",
    "            csheet = child.children[1].value\n",
    "            col = child.children[3].value\n",
    "            val = child.children[5].value\n",
    "            if val == '*Ctrl same as Trt*':\n",
    "                val = None\n",
    "            conditions.append((csheet, col, val))\n",
    "        dic[name] = {\n",
    "            'sheet': sheet,\n",
    "            'column': column,\n",
    "            'value': value,\n",
    "            'occurence': occurence,\n",
    "            'conditions': conditions\n",
    "        }\n",
    "    return dic\n",
    "\n",
    "# refs = buildMetaRef(dfdic)\n",
    "# display(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# queries = getQueries(refs)\n",
    "# print(queries)\n",
    "# extractQueries(queries, dfdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract treatments according to query\n",
    "def extractTreatments(trtOut):\n",
    "    global compdict, dfdic, queries\n",
    "    t0 = time.time()\n",
    "    trtOut.clear_output()\n",
    "    expOut.clear_output() # also clear exports\n",
    "    with trtOut:\n",
    "        print('processing...', end='')\n",
    "        queries = getQueries(refs)\n",
    "        compdict = extractQueries(queries, dfdic)\n",
    "    dfsum = pd.DataFrame(columns=['name', 'sheet', 'value', 'occurence', 'conditions',\n",
    "                                  'number of experiments', 'number of pairs'])\n",
    "    for key in queries:\n",
    "        query = queries[key]\n",
    "        pairs = compdict[key]\n",
    "        dfsum = dfsum.append({\n",
    "            'name': key,\n",
    "            'sheet': query['sheet'],\n",
    "            'column': query['column'],\n",
    "            'value': query['value'],\n",
    "            'occurence': query['occurence'],\n",
    "            'conditions': ' & '.join([':'.join([str(a) for a in b])\n",
    "                                      for b in query['conditions']]),\n",
    "            'number of experiments': pairs['expid'].unique().shape[0],\n",
    "            'number of pairs': pairs.shape[0]\n",
    "        }, ignore_index=True)\n",
    "    with trtOut:\n",
    "        print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "        display(dfsum[['name', 'number of experiments', 'number of pairs']])\n",
    "\n",
    "\n",
    "# compdict = {}\n",
    "# queries = {}\n",
    "# trtOut = Output()\n",
    "# extractTreatmentBtn = Button(description='Get treatments', style= {'button_color':'orange'})\n",
    "# def func(_):\n",
    "#     extractTreatments(trtOut)\n",
    "# extractTreatmentBtn.on_click(func)\n",
    "# VBox([extractTreatmentBtn, trtOut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns that must be the same in pairwise comparison\n",
    "# select type of effect sizes (diff or ratio) and if log or not\n",
    "# numChoices = []\n",
    "# for sheet in dbdic:\n",
    "#     for key in dbdic[sheet]:\n",
    "#         if dbdic[sheet][key] == 'number' and 'data-' in sheet:\n",
    "#             numChoices.append(sheet + ' | ' + key)\n",
    "# numRadio = Dropdown(options=numChoices, layout=Layout(width='70%'))\n",
    "# esType = RadioButtons(options=['difference', 'ratio'])\n",
    "# esLog = RadioButtons(options=['yes', 'no'], value='no')\n",
    "# metaOut = Output()\n",
    "# def runMetaBtnFunc(a):\n",
    "#     global dfmeta\n",
    "#     metaOut.clear_output()\n",
    "#     with metaOut:\n",
    "#         plotES()\n",
    "# runMetaBtn = Button(description='Plot Effect sizes',\n",
    "#                     style= {'button_color':'orange'})\n",
    "# runMetaBtn.on_click(runMetaBtnFunc)\n",
    "# metaBox = VBox([HBox([VBox([Label('Numerical column for effect sizes:'), numRadio, runMetaBtn],\n",
    "#                      layout=Layout(width='33%')),\n",
    "#                 VBox([Label('How to compute ES?'), esType,\n",
    "#                       Label('Apply log on numeric value?'), esLog], layout=Layout(width='40%')),\n",
    "#                ], layout=Layout(height='110%')), metaOut])\n",
    "\n",
    "#display(metaBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a flat dataframe with _C columns vs _T columns\n",
    "\n",
    "def buildMetaDF(dfdic, compdicto, supcols=[]):\n",
    "    \"\"\"Build horizontal dataframe for meta-analysis.\n",
    "    \"\"\"\n",
    "    # collect other supplemental informative columns\n",
    "    mcols = [  # mandatory columns that should always be there\n",
    "        'reference | Data entry person',\n",
    "        'reference | Data entry person email',\n",
    "        'reference | Publication ID',\n",
    "    ]\n",
    "    for mcol in mcols:\n",
    "        if mcol not in supcols:\n",
    "            supcols.append(mcol)\n",
    "    if len(supcols) > 0:\n",
    "        dfsc = pd.DataFrame([a.split(' | ') for a in supcols], \n",
    "                            columns=['sheet', 'column'])\n",
    "    else:\n",
    "        dfsc = pd.DataFrame(columns=['sheet', 'column'])\n",
    "        # for sheet in list(dfdic.keys())[2:-1]:\n",
    "        #     cols = dfdic[sheet].columns.tolist()\n",
    "        #     sdf = pd.DataFrame(cols, columns=['column'])\n",
    "        #     sdf['sheet'] = sheet\n",
    "        #     dfsc = dfsc.append(sdf, ignore_index=True)\n",
    "\n",
    "    # if compdict empty just take all expids\n",
    "    isMA = True\n",
    "    compdict = dicCopy(compdicto)\n",
    "    if len(compdict.keys()) == 0 or 'all' in compdict.keys():\n",
    "        compdict = {}  # clear out all keys\n",
    "        compdict['all'] = dfdic['treatment'][['Experiment ID', 'Treatment ID']].rename(\n",
    "            columns={'Experiment ID': 'expid', 'Treatment ID': 'treatid_C'})\n",
    "        isMA = False\n",
    "\n",
    "    # concatenation function for metadata\n",
    "    def concat(x):\n",
    "        xs = [str(a) for a in x]\n",
    "        if all([a == xs[0] for a in xs]):  # if all values are the same, just put it once\n",
    "            return xs[0]\n",
    "        else:\n",
    "            return ' | '.join(xs)\n",
    "\n",
    "    dfs = []\n",
    "    for query in compdict:\n",
    "        df = compdict[query].rename(columns={'expid': 'Experiment ID'})\n",
    "        df['pairedComparison'] = np.arange(df.shape[0]) + 1\n",
    "        df['query'] = query\n",
    "\n",
    "        # experiment specific metadata\n",
    "        for sheet in ['experiment', 'soil-type', 'reference']:\n",
    "            ldf = dfdic[sheet]\n",
    "            cols = dfsc[dfsc['sheet'].eq(sheet)]['column'].tolist()\n",
    "            if len(cols) > 0:\n",
    "                cols = cols + ['Experiment ID'] if 'Experiment ID' not in cols else cols\n",
    "                df = pd.merge(df, ldf[cols], on='Experiment ID', how='left')\n",
    "\n",
    "        # treatment specific metadata\n",
    "        for sheet in ['treatment', 'tillage', 'crops', 'amendment', 'irrigation']:\n",
    "            ldf = dfdic[sheet]\n",
    "            cols = dfsc[dfsc['sheet'].eq(sheet)]['column'].tolist()\n",
    "            if len(cols) > 0:\n",
    "                cols = cols + ['Experiment ID'] if 'Experiment ID' not in cols else cols\n",
    "                cols = cols + ['Treatment ID'] if 'Treatment ID' not in cols else cols\n",
    "                ldf = ldf.groupby(['Experiment ID', 'Treatment ID']).agg(concat).reset_index()\n",
    "\n",
    "                # for control\n",
    "                df = pd.merge(df, ldf[cols].add_suffix('_C'), how='left',\n",
    "                              left_on=['Experiment ID', 'treatid_C'],\n",
    "                              right_on=['Experiment ID_C', 'Treatment ID_C'])\n",
    "                df = df.drop(['Experiment ID_C', 'Treatment ID_C'], axis=1)\n",
    "\n",
    "                # for treatment\n",
    "                if isMA:\n",
    "                    df = pd.merge(df, ldf[cols].add_suffix('_T'), how='left',\n",
    "                                  left_on=['Experiment ID', 'treatid_T'],\n",
    "                                  right_on=['Experiment ID_T', 'Treatment ID_T'])\n",
    "                    df = df.drop(['Experiment ID_T', 'Treatment ID_T'], axis=1)\n",
    "\n",
    "        # add data-soil\n",
    "        # we start by merging the data-soil so that if data is missing from data-crop, SOC can still be in the flat format\n",
    "        ldf = dfdic['data-soil']\n",
    "        rdic = {\n",
    "            'Sampling year_C': 'Sampling year',\n",
    "            'Sampling year_T': 'Sampling year',\n",
    "            'Depth from_C': 'Depth from',\n",
    "            'Depth from_T': 'Depth from',\n",
    "            'Depth to_C': 'Depth to',\n",
    "            'Depth to_T': 'Depth to',\n",
    "            'Publication ID_C': 'Publication ID',\n",
    "            'Publication ID_T': 'Publication ID',\n",
    "        }\n",
    "\n",
    "        # for control\n",
    "        df = pd.merge(df, ldf.add_suffix('_C').rename(columns=rdic), how='left',\n",
    "                      left_on=['Experiment ID', 'treatid_C', 'Publication ID'],\n",
    "                      right_on=['Experiment ID_C', 'Treatment ID_C', 'Publication ID'])\n",
    "        df = df.drop(['Experiment ID_C', 'Treatment ID_C'], axis=1)\n",
    "\n",
    "        # for treatment\n",
    "        if isMA:\n",
    "            df = pd.merge(df, ldf.add_suffix('_T').rename(columns=rdic), how='left',\n",
    "                          left_on=['Experiment ID', 'treatid_T', 'Publication ID',\n",
    "                                   'Sampling year', 'Depth from', 'Depth to'],\n",
    "                          right_on=['Experiment ID_T', 'Treatment ID_T', 'Publication ID',\n",
    "                                    'Sampling year', 'Depth from', 'Depth to'])\n",
    "            df = df.drop(['Experiment ID_T', 'Treatment ID_T'], axis=1)\n",
    "\n",
    "\n",
    "        # add data-soil\n",
    "        ldf = dfdic['data-crop']\n",
    "\n",
    "        # for control\n",
    "        df = pd.merge(df, ldf.add_suffix('_C').rename(columns=rdic), how='left',\n",
    "                      left_on=['Experiment ID', 'treatid_C', 'Publication ID', 'Sampling year'],\n",
    "                      right_on=['Experiment ID_C', 'Treatment ID_C', 'Publication ID', 'Sampling year'])\n",
    "        df = df.drop(['Experiment ID_C', 'Treatment ID_C'], axis=1)\n",
    "\n",
    "        # for treatment\n",
    "        if isMA:\n",
    "            df = pd.merge(df, ldf.add_suffix('_T').rename(columns=rdic), how='left',\n",
    "                          left_on=['Experiment ID', 'treatid_T', 'Publication ID', 'Sampling year'],\n",
    "                          right_on=['Experiment ID_T', 'Treatment ID_T', 'Publication ID', 'Sampling year'])                              \n",
    "            df = df.drop(['Experiment ID_T', 'Treatment ID_T'], axis=1)\n",
    "\n",
    "        dfs.append(df)\n",
    "    dfm = pd.concat(dfs)\n",
    "\n",
    "    # drop useless id columns (crop id, rotation, pubid)\n",
    "\n",
    "    # drop nan rows\n",
    "    dfm = dfm.replace(to_replace='nan', value=np.nan, regex=False)\n",
    "    dcols = ['Harvested yield', 'SOC conc', 'SOC stock']\n",
    "    colsC = [a + '_C' for a in dcols]\n",
    "    colsT = [a + '_T' for a in dcols]\n",
    "    if isMA:\n",
    "        i2keep = dfm[colsC].notnull().any(1) & dfm[colsT].notnull().any(1)\n",
    "    else:\n",
    "        dfm = dfm.rename(columns=dict(zip(dfm.columns, [a.replace('_C', '') for a in dfm.columns])))\n",
    "        i2keep = dfm[dcols].notnull().any(1)\n",
    "    #print('{:d}/{:d} rows kept (rows with data associated)'.format(\n",
    "    #    i2keep.sum(), i2keep.shape[0]))\n",
    "    dfm = dfm[i2keep].reset_index(drop=True)\n",
    "    \n",
    "    # make columns underCase\n",
    "    \n",
    "    return dfm\n",
    "\n",
    "#compdict = {}\n",
    "#df = buildMetaDF(dfdic, compdict)#['experiment | Latitude', 'soil-type | Soil group WRB','irrigation | Irrigation method'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildMetaDf(supcols=[]):\n",
    "#     \"\"\"Build dataframe with control vs treatment.\n",
    "#     \"\"\"\n",
    "#     global dfdic, compdict\n",
    "\n",
    "#     # collect other supplemental informative columns\n",
    "#     dfsc = pd.DataFrame([a.split(' | ') for a in supcols], \n",
    "#                         columns=['sheet', 'column'])\n",
    "\n",
    "#     # get column with the target numeric on which compute ES\n",
    "#     numsheet, numcol = numRadio.value.split(' | ')\n",
    "#     dfsc = dfsc.append({'sheet': numsheet, 'column': numcol}, ignore_index=True)\n",
    "\n",
    "#     dfmeta = pd.DataFrame(columns=['query', 'expid', 'treatid_C', 'treatid_T',\n",
    "#                                   numcol + '_C', numcol + '_T', 'ES'])\n",
    "#     dfstack = pd.DataFrame()\n",
    "    \n",
    "#     pairCounter = 0\n",
    "#     for key in compdict:\n",
    "#         # add columns involved in the query\n",
    "#         sheet = queries[key]['sheet']\n",
    "#         col = queries[key]['column']\n",
    "#         dfsc = dfsc.append({'sheet': sheet, 'column': col}, ignore_index=True)\n",
    "        \n",
    "#         # add additional columns which are in the same sheet\n",
    "#         ccols = [b for a, b, c in queries[key]['conditions'] if a == sheet]\n",
    "#         for a in ccols:\n",
    "#             dfsc = dfsc.append({'sheet': sheet, 'column': a}, ignore_index=True)\n",
    "\n",
    "#         # ISSUE: with rotation or multiple rows per treatments (e.g. amendments),\n",
    "#         # it's not possible to be sure that treatment and control will be on same rows\n",
    "#         # an option would be to have a stacked design as we had with pc columns or so\n",
    "\n",
    "#         # OPTION 1: stacked\n",
    "#         for l in range(compdict[key].shape[0]):\n",
    "#             expid = compdict[key]['expid'][l]\n",
    "#             pairCounter += 1\n",
    "\n",
    "#             # add metadata for the control\n",
    "#             treatidC = compdict[key]['treatid_C'][l]\n",
    "#             subdf = pd.DataFrame()\n",
    "#             for j, sheet in enumerate(dfsc['sheet'].unique()):\n",
    "#                 cols = dfsc[dfsc['sheet'] == sheet]['column'].to_list()\n",
    "#                 if 'Treatment ID' in dfdic[sheet].columns:\n",
    "#                     cols += ['Experiment ID', 'Treatment ID']\n",
    "#                     df = dfdic[sheet][cols]\n",
    "#                     ie = (df['Experiment ID'] == expid) & (df['Treatment ID'] == treatidC)\n",
    "#                 else:\n",
    "#                     cols += ['Experiment ID']\n",
    "#                     df = dfdic[sheet][cols]\n",
    "#                     ie = (df['Experiment ID'] == expid)\n",
    "#                 if j == 0:\n",
    "#                     subdf = df[ie]\n",
    "#                 else:\n",
    "#                     subdf = pd.merge(subdf, df[ie], how='outer')\n",
    "#             subdf['query'] = key\n",
    "#             subdf['pc'] = -pairCounter\n",
    "#             dfstack = dfstack.append(subdf)\n",
    "\n",
    "#             # add metadata for the treatment\n",
    "#             treatidT = compdict[key]['treatid_T'][l]\n",
    "#             subdf = pd.DataFrame()\n",
    "#             for j, sheet in enumerate(dfsc['sheet'].unique()):\n",
    "#                 cols = dfsc[dfsc['sheet'] == sheet]['column'].to_list()\n",
    "#                 if 'Treatment ID' in dfdic[sheet].columns:\n",
    "#                     cols += ['Experiment ID', 'Treatment ID']\n",
    "#                     df = dfdic[sheet][cols]\n",
    "#                     ie = (df['Experiment ID'] == expid) & (df['Treatment ID'] == treatidT)\n",
    "#                 else:\n",
    "#                     cols += ['Experiment ID']\n",
    "#                     df = dfdic[sheet][cols]\n",
    "#                     ie = (df['Experiment ID'] == expid)\n",
    "#                 if j == 0:\n",
    "#                     subdf = df[ie]\n",
    "#                 else:\n",
    "#                     subdf = pd.merge(subdf, df[ie], how='outer')\n",
    "#             subdf['query'] = key\n",
    "#             subdf['pc'] = pairCounter\n",
    "#             dfstack = dfstack.append(subdf)\n",
    "\n",
    "#         # OPTION 2: ctrls vs trt but not addition metadata\n",
    "#         # NOTE: we take all values (even if multiple years)\n",
    "#         subdf = compdict[key]\n",
    "#         dfnum = dfdic[numsheet]\n",
    "#         colindex = ['Experiment ID', 'Treatment ID']\n",
    "\n",
    "#         # add value for control\n",
    "#         subdf = pd.merge(subdf, dfnum[colindex + [numcol]],\n",
    "#                          left_on=['expid', 'treatid_C'],\n",
    "#                          right_on=colindex).rename(\n",
    "#             columns={numcol: numcol + '_C'}).drop(colindex, axis=1)\n",
    "\n",
    "#         # add value for treatment\n",
    "#         subdf = pd.merge(subdf, dfnum[colindex + [numcol]],\n",
    "#                          left_on=['expid', 'treatid_T'],\n",
    "#                          right_on=colindex).rename(\n",
    "#             columns={numcol: numcol + '_T'}).drop(colindex, axis=1)\n",
    "\n",
    "#         # compute effect size\n",
    "#         valC = subdf[numcol + '_C']\n",
    "#         valT = subdf[numcol + '_T']\n",
    "#         inan = ~np.isnan(valC) & ~np.isnan(valT)\n",
    "#         if esType == 'difference':\n",
    "#             if esLog == 'yes':\n",
    "#                 subdf.loc[inan, 'ES'] = np.log10(valC[inan]) - np.log10(valT[inan])\n",
    "#             else:\n",
    "#                 subdf.loc[inan, 'ES'] = valC[inan] - valT[inan]\n",
    "#         else:\n",
    "#             if esLog == 'yes':\n",
    "#                 subdf.loc[inan, 'ES'] = np.log10(valC[inan]) / np.log10(valT[inan])\n",
    "#             else:\n",
    "#                 subdf.loc[inan, 'ES'] = valC[inan] / valT[inan]\n",
    "\n",
    "#         # add query and append to dfmeta\n",
    "#         subdf['query'] = key\n",
    "#         dfmeta = dfmeta.append(subdf)\n",
    "\n",
    "#     # remove NaN\n",
    "#     dfmeta = dfmeta[dfmeta['ES'].notnull()].reset_index(drop=True)\n",
    "\n",
    "#     return dfmeta, dfstack\n",
    "\n",
    "#dfmeta, dfstack = buildMetaDf(['experiment | Latitude', 'experiment | Longitude'])\n",
    "#display(dfmeta)\n",
    "#display(dfstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: what if multiple per year value? how to compute ES?\n",
    "# mean of ES is done for now but we could do the mean of value and then compute ES\n",
    "# def plotES():\n",
    "#     global dfdic, comdict, dfmeta, dfstack\n",
    "#     if 'query' not in dfmeta.columns:\n",
    "#         print('Please first specify control and treatments in the Query tab')\n",
    "#         return\n",
    "#     # compute back the dfmeta if we have a different numcol\n",
    "#     print('running...', end='')\n",
    "#     dfmeta, dfstack = buildMetaDf()\n",
    "#     print('done')\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.set_title('Effect size on ' + numRadio.value.split(' | ')[1])\n",
    "#     ylabs = []\n",
    "#     if esType.value == 'difference':\n",
    "#         ax.axvline(0, linestyle='--', color='k')\n",
    "#     else:\n",
    "#         ax.axvline(1, linestyle='--', color='k')\n",
    "#     gmean = dfmeta.groupby(['query', 'expid', 'treatid_C', 'treatid_T']).mean().reset_index()\n",
    "#     for i, query in enumerate(dfmeta['query'].unique()):\n",
    "#         ie = gmean['query'] == query\n",
    "#         if np.sum(ie) == 0:\n",
    "#             print('No values found for ' + query)\n",
    "#         ax.errorbar(gmean[ie]['ES'].mean(), i, xerr=gmean[ie]['ES'].sem(), marker='o', label=query)\n",
    "#         ylabs.append('{:s} ({:d})'.format(query, ie.sum()))\n",
    "#     ax.set_xlabel('Effect size') # units if difference, nothing if ratio\n",
    "#     ax.set_yticks(np.arange(len(ylabs)))\n",
    "#     ax.set_yticklabels(ylabs);\n",
    "#     #ax.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#plotES(dfmeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a selection of additional meta-data columns to be added to the merged or C vs T export format\n",
    "\n",
    "ids = ['Experiment ID', 'Treatment ID', 'Crop ID', 'Rotation', 'Publication ID']\n",
    "\n",
    "def buildSelection(dfdic):\n",
    "    scols = []\n",
    "    for sheet in list(dfdic.keys())[2:-3]:  # all data-crop and data-soil are included by default\n",
    "        cols = dfdic[sheet].columns\n",
    "        ie1 = cols.isin(ids) | cols.isin(['Data entry person', 'Data entry person email'])\n",
    "        scols +=  (sheet + ' | ' + cols[~ie1]).tolist()\n",
    "    checkboxes = [Checkbox(value=True, description=a, indent=False) for a in scols]\n",
    "    def checkall(a):\n",
    "        for c in checkboxes:\n",
    "            c.value = a['new']\n",
    "    allcheck = Checkbox(value=True, description='Select all', indent=False)\n",
    "    allcheck.observe(checkall, names='value')\n",
    "    return VBox([allcheck] + checkboxes)\n",
    "\n",
    "# def getMergedDf(dfdic, vbox):\n",
    "#     selection = [child.description.split(' | ') for child in vbox.children[1:] if child.value is True]\n",
    "#     dfsel = pd.DataFrame(selection, columns=['sheet', 'column'])\n",
    "#     sheets = dfsel['sheet'].unique()\n",
    "#     dfm = pd.DataFrame()\n",
    "#     for i, sheet in enumerate(sheets):\n",
    "#         cols = dfsel[dfsel['sheet'] == sheet]['column'].tolist()\n",
    "#         cols += ids\n",
    "#         cols = pd.Series(cols)\n",
    "#         df = dfdic[sheet]\n",
    "#         cols = cols[cols.isin(df.columns.tolist())]\n",
    "#         if i == 0:\n",
    "#             dfm = df[cols]\n",
    "#         else:\n",
    "#             dfm = pd.merge(dfm, df[cols], how='outer')\n",
    "#     return dfm\n",
    "\n",
    "\n",
    "#vbox = buildSelection(dfdic)\n",
    "#vbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the filtered excel file (same format as the template)\n",
    "def buildFilteredDB(dfdic, compdicto, name='Filtered DB', fname='filtered-db.xlsx'):\n",
    "    # if compdict empty just take all expids\n",
    "    compdict = dicCopy(compdicto)\n",
    "    if len(compdict.keys()) == 0 or 'all' in compdict.keys():\n",
    "        compdict = {}  # clear out all keys\n",
    "        compdict['all'] = dfdic['treatment'][['Experiment ID', 'Treatment ID']].rename(\n",
    "            columns={'Experiment ID': 'expid', 'Treatment ID': 'treatid_C'})\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        fpath = os.path.join(td + fname)\n",
    "        writer = pd.ExcelWriter(fpath, engine='xlsxwriter')\n",
    "        for tab, df in dfdic.items():\n",
    "            if tab in ['experiment', 'reference', 'soil-type', 'treatment', 'tillage', 'crops',\n",
    "                       'amendment', 'irrigation', 'grazing', 'pest-weed',\n",
    "                       'soil-crop-measurement', 'data-crop', 'data-soil']:\n",
    "\n",
    "                # filter to only keep the row relevant to queries\n",
    "                if 'Experiment ID' not in df.columns:\n",
    "                    ie = np.ones(df.shape[0], dtype=bool)\n",
    "                else:\n",
    "                    ie = np.zeros(df.shape[0], dtype=bool)\n",
    "                    for key in compdict:\n",
    "                        dfcol = compdict[key]\n",
    "                        if 'Treatment ID' in df.columns:\n",
    "                            for expid in dfcol['expid'].unique():\n",
    "                                if 'treatid_T' in dfcol.columns:\n",
    "                                    treatids = dfcol[dfcol['expid'] == expid][['treatid_C', 'treatid_T']].values.flatten()\n",
    "                                else:\n",
    "                                    treatids = dfcol[dfcol['expid'] == expid]['treatid_C'].values\n",
    "                                ie = ie | ((df['Experiment ID'] == expid) & (df['Treatment ID'].isin(treatids)))\n",
    "                        else:\n",
    "                            ie = ie | (df['Experiment ID'].isin(dfcol['expid'].tolist()))\n",
    "                df[ie].to_excel(writer, sheet_name=tab, index=False)\n",
    "        writer.save()\n",
    "#         fname = datadir + 'template-blank.xlsx'\n",
    "#         workbook = load_workbook(filename=fname)\n",
    "#         sheetNames = list(dfdic.keys())[2:-1]\n",
    "#         for sheetName in sheetNames:\n",
    "#             sheet = workbook[sheetName]\n",
    "#             for row in dataframe_to_rows(dfdic[sheetName], index=False, header=False):\n",
    "#                 sheet.append(row)\n",
    "#         workbook.save(datadir + 'carboseq-wp2-db.xlsx')\n",
    "        with open(fpath,  'rb') as f:\n",
    "            data = f.read()\n",
    "    b64 = base64.b64encode(data)\n",
    "    payload = b64.decode()\n",
    "\n",
    "    html_button = '''\n",
    "    <a download=\"{fname}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-info\">{name}</button>\n",
    "    </a>\n",
    "    '''.format(payload=payload, fname=fname, name=name)\n",
    "\n",
    "    return HTML(html_button)\n",
    "\n",
    "#buildFilteredDB(dfdic, compdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDownload(df, name='Download File', fname='df.xlsx'):\n",
    "    t0 = time.time()\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        fpath = os.path.join(td + fname)\n",
    "        df.to_excel(fpath, index=False)  # takes some time but csv takes more time to render in base64\n",
    "        #with ZipFile(fpath.replace('.csv', '.zip'), mode='w') as myzip:\n",
    "        #    myzip.write(fpath, arcname=fname.replace('.csv', ''))\n",
    "        with open(fpath,  'rb') as f:\n",
    "            data = f.read()\n",
    "    b64 = base64.b64encode(data)\n",
    "    payload = b64.decode()\n",
    "\n",
    "    html_button = '''\n",
    "    <a download=\"{fname}\" href=\"data:text/xlsx;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-info\">{name}</button>\n",
    "    </a>\n",
    "    '''.format(payload=payload, fname=fname, name=name)\n",
    "\n",
    "    return HTML(html_button)\n",
    "\n",
    "#DownloadDownload(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b998c17a474790b4c15f10caf04190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Label(value='Please load the database as .xlsx file.'), HBox(children=(FileUpload…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# global variables\n",
    "dfdic = {}\n",
    "dfdico = {} # original only for reseting dfdic\n",
    "df = pd.DataFrame()\n",
    "dfmeta = pd.DataFrame() # for meta-analysis\n",
    "dfstack = pd.DataFrame() # stacked version of paired dataframe\n",
    "compdict = {}\n",
    "queries = {}\n",
    "refs = None\n",
    "version = ''\n",
    "expOut = None\n",
    "\n",
    "# upload button\n",
    "def loadBtnFunc(btn):\n",
    "    global dfdic, dfdico, dfmeta, dfstack, mainLayout, refs, version, expOut\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        if gsurl.value != '':\n",
    "            dfdic, version = readExcel(gsurl.value)\n",
    "        elif len(uploadBtn.value) > 0:\n",
    "            dfdic, version = readExcel(uploadBtn.value[0]['content'].tobytes())\n",
    "            #with open('t.xlsx', 'wb') as f: # faster but less robust\n",
    "            #    f.write(upload.data[0])\n",
    "            #dfdic = readExcel2('t.xlsx')\n",
    "        print('database version: ', version)\n",
    "        \n",
    "        # create backup copy\n",
    "        dfdico = dicCopy(dfdic)\n",
    "        \n",
    "        # reset upload button\n",
    "        uploadBtn.value = []\n",
    "\n",
    "        # remove the 'unnamed columns'\n",
    "        for sheet in dfdic:\n",
    "            cols = dfdic[sheet].columns\n",
    "            dfdic[sheet] = dfdic[sheet].drop(cols[cols.str.contains('Unnamed')], axis=1)\n",
    "\n",
    "        # force float type\n",
    "        for sheet in dbdic.keys():\n",
    "            for col in dbdic[sheet].keys():\n",
    "                if (dbdic[sheet][col] == 'number'):\n",
    "                    try:\n",
    "                        dfdic[sheet][col].astype(float)\n",
    "                    except Exception as e:\n",
    "                        dfdic[sheet][col] = dfdic[sheet][col].apply(tofloat)\n",
    "                        print('had to force ', sheet, '>', col, 'to be float:', str(e))\n",
    "\n",
    "        # make a backup to be used if we reset the filters\n",
    "        dfdico = dfdic.copy()\n",
    "\n",
    "        # build descriptive stats\n",
    "        #print('\\nThe plot below shows the number of treatments that have investigated a specific'\n",
    "        #      ' factor as well as the ones that have investigated many.')\n",
    "        #plotFactor(dfdic)\n",
    "        showMap(dfdic)\n",
    "\n",
    "        # but back mainLayout to one single tab\n",
    "        mainLayout.children = mainLayout.children[:1]\n",
    "\n",
    "        # build filtering\n",
    "        filters = buildFilters()\n",
    "        mainLayout.children += (VBox([\n",
    "            Label('Add data filters. The filters are always applied on the initial database uploaded. '\n",
    "                  'You can then further explored the filtered data by creating queries (Query tab).'), filters]), )\n",
    "\n",
    "        # creating queries\n",
    "        refs = buildMetaRef(dfdic)\n",
    "        trtOut = Output()\n",
    "        extractTreatmentBtn = Button(description='Get treatments', style= {'button_color':'orange'})\n",
    "        def func(_):\n",
    "            global dfmeta, dfstack\n",
    "            extractTreatments(trtOut)\n",
    "            dfmeta, dfstack = buildMetaDf()\n",
    "        extractTreatmentBtn.on_click(func)\n",
    "        trtInstructions = Output()\n",
    "        with trtInstructions:\n",
    "            display(Markdown('''\n",
    "This tab helps to query the database by defining what you want to compare in a query. \n",
    "A query is formed by a reference/control (button 'Add reference') where you defined the sheet, column and value you want. \n",
    "You can then specified the 'occurence' of the value (this value against other, presence or absence, 1 vs more occurence of the value). \n",
    "The code will extract the reference/control rows and look for their corresponding 'treatment' rows, thus forming pairs of 'control vs treatment'.\n",
    "To further restrain the comparison, conditions can be added to force both 'control' and 'treatment' rows to share the same or a specific value for given column.\n",
    "\n",
    "Examples:\n",
    "- tillage vs no-tillage:\n",
    "    - sheet: tillage\n",
    "    - column: Tillage type\n",
    "    - value: Zero tillage\n",
    "    - occurence: this value vs others\n",
    "    - conditions: None\n",
    "- cover crops vs no cover crop (inside same rotation):\n",
    "    - sheet: crops\n",
    "    - column: Crop type\n",
    "    - value: Cover crop\n",
    "    - occurence: presence or absence\n",
    "    - conditions: Rotation: *Ctrl same as Trt*\n",
    "'''))\n",
    "        mainLayout.children += (VBox([trtInstructions, refs, extractTreatmentBtn, trtOut]), )\n",
    "\n",
    "        # build meta-analysis part\n",
    "        # mainLayout.children += (\n",
    "        #         VBox([Label('Select a numeric column on from which to compute the effect sizes.'),\n",
    "        #               metaBox]),)\n",
    "\n",
    "        # build export part\n",
    "        vbox = buildSelection(dfdic)\n",
    "\n",
    "        def expBtnFunc(a):\n",
    "            global dfmeta, dfstack\n",
    "            expOut.clear_output()\n",
    "\n",
    "            with expOut:\n",
    "                # generate the merged dataframe\n",
    "                print('creating merged file...', end='')\n",
    "                t0 = time.time()\n",
    "                #dfm = getMergedDf(dfdic, vbox)\n",
    "                print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "\n",
    "                # generate the dfmeta and dfstack with the supplementary columns\n",
    "                print('creating flat DB...', end='')\n",
    "                t0 = time.time()\n",
    "                supcols = [child.description for child in vbox.children[1:] if child.value is True]\n",
    "                dfmeta = buildMetaDF(dfdic, compdict, supcols=supcols)\n",
    "                #dfmeta, dfstack = buildMetaDf(supcols=supcols)\n",
    "                print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "\n",
    "                # display the button to download the files\n",
    "                print('creating download buttons...', end='')\n",
    "                t0 = time.time()\n",
    "                display(buildFilteredDB(dfdic, compdict, 'Filtered DB', 'filtered-db-' + version + '.xlsx'))\n",
    "                #display(prepareDownload(dfm, 'Merged file', 'merged-db.xlsx'))\n",
    "                display(prepareDownload(dfmeta, 'Flat DB', 'flat-db-' + version + '.xlsx'))\n",
    "                #fname = 'meta-c-vs-t.xlsx'\n",
    "                #dfmeta.to_excel(fname, index=False)\n",
    "                #display(FileLink(fname))\n",
    "                print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "\n",
    "        expBtn = Button(description='Generate exports')\n",
    "        expBtn.on_click(expBtnFunc)\n",
    "        expOut = Output()\n",
    "        exports = HBox([vbox,\n",
    "                        VBox([expBtn, expOut])])\n",
    "\n",
    "        # instructions\n",
    "        trtInstructions = Output()\n",
    "        with trtInstructions:\n",
    "            display(Markdown('''\n",
    "Only the rows relevant to the queries (Query tab) will be exported. If no queries were done, the entire database (after filtering) is exported.\n",
    "Two export format are available: a \"Filtered DB\" format which is an .xlsx file with similar tab structure than the database or\n",
    "a \"Flat DB\" format which is an .xlsx file with one single tab in which the information is stacked. If queries are made,\n",
    "the \"Flat DB\" format will contains columns with _C (for control) and _T for treatment so that this file can be used for meta-analysis more easily.\n",
    "By default, only the columns in \"data-soil\" and \"data-crop\" tabs and also columns relevant to the \"Data entry person\" are included in the \"Flat DB\". You can select additional column to be added\n",
    "with the checkboxes below. Do not forget to regenerate the exports if you change the selection of columns to be exported.\n",
    "'''))\n",
    "\n",
    "        mainLayout.children += (\n",
    "            VBox([trtInstructions, exports]),\n",
    "        )\n",
    "\n",
    "        # filter and export tab\n",
    "        fInstructions = Output()\n",
    "        with fInstructions:\n",
    "            display(Markdown('''\n",
    "Import an excel file (.xlsx) containing two ('Experiment ID' and 'Treatment ID') or three columns ('Experiment ID', 'Treatment ID_C', 'Treatment ID_T') to operate a manual selection. \n",
    "The **initially uploaded database** will be filtered to only keep the selected 'Experiment ID' and 'Treatment ID'.\n",
    "Export can then be done as 'Filtered DB' format (excel with multiple tabs) \n",
    "or as 'Flat DB' format (one sheet, includes all metadata columns specified in tab 'export').\n",
    "'''))\n",
    "\n",
    "        fexports = Output()\n",
    "\n",
    "        def fbtnFunc(a):\n",
    "            global compdict, dfdico, dfdic\n",
    "            fexports.clear_output()\n",
    "            with fexports:\n",
    "                # read in data\n",
    "                print('reading...', end='')\n",
    "                dff = pd.read_excel(fbtn.value[0]['content'].tobytes())\n",
    "                fbtn.value = []\n",
    "                print('done')\n",
    "\n",
    "                # filtered data\n",
    "                dfdic2 = dicCopy(dfdico)\n",
    "                for sheet in list(dbdic.keys())[3:-2]:\n",
    "                    df = dfdic2[sheet].copy()\n",
    "                    if 'Treatment ID' in df.columns:\n",
    "                        if 'Treatment ID' in dff.columns:  # only two columns specified\n",
    "                            ie = (df['Experiment ID'].isin(dff['Experiment ID'].unique().tolist())\n",
    "                                  & df['Treatment ID'].isin(dff['Treatment ID'].tolist()))\n",
    "                        elif 'Treatment ID_C' in dff.columns:  # three columns format\n",
    "                            ie = (df['Experiment ID'].isin(dff['Experiment ID'].unique().tolist())\n",
    "                                  & (df['Treatment ID'].isin(dff['Treatment ID_C'].tolist())\n",
    "                                    | df['Treatment ID'].isin(dff['Treatment ID_T'].tolist())))\n",
    "                        else:  # select all treatments from the given experiment id list\n",
    "                            ie = df['Experiment ID'].isin(dff['Experiment ID'].unique().tolist())\n",
    "                    else:\n",
    "                        ie = df['Experiment ID'].isin(dff['Experiment ID'].unique().tolist())\n",
    "                    dfdic2[sheet] = df[ie].reset_index(drop=True)\n",
    "\n",
    "                # generate the flat DB format with the supplementary columns\n",
    "                print('creating flat DB...', end='')\n",
    "                t0 = time.time()\n",
    "                supcols = [child.description for child in vbox.children[1:] if child.value is True]\n",
    "                if 'Treatment ID_C' in dff.columns:\n",
    "                     compdict2 = {'selection': dff.rename(columns={\n",
    "                        'Experiment ID': 'expid',\n",
    "                        'Treatment ID': 'treatid_C',\n",
    "                        'Treatment ID_C': 'treatid_C',\n",
    "                        'Treatment ID_T': 'treatid_T'\n",
    "                    })}\n",
    "                else:\n",
    "                    compdict2 = {}\n",
    "                dfmeta = buildMetaDF(dfdic2, compdict2, supcols=supcols)\n",
    "                print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "\n",
    "                # display the button to download the files\n",
    "                print('creating download buttons...', end='')\n",
    "                t0 = time.time()\n",
    "                display(buildFilteredDB(dfdic2, {}, 'Filtered DB', 'filtered-db-' + version + '.xlsx'))\n",
    "                display(prepareDownload(dfmeta, 'Flat DB', 'flat-db-' + version + '.xlsx'))\n",
    "                #fname = 'meta-c-vs-t.xlsx'\n",
    "                #dfmeta.to_excel(fname, index=False)\n",
    "                #display(FileLink(fname))\n",
    "                #display(prepareDownload(dfstack, 'Meta stacked', 'meta-stacked.xlsx'))\n",
    "                print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "                \n",
    "        fbtn = FileUpload(description='Selection file', accept='.xlsx',\n",
    "                          multiple=False, style= {'button_color':'orange'})\n",
    "        fbtn.observe(fbtnFunc, names='value')\n",
    "\n",
    "        mainLayout.children += (\n",
    "            VBox([fInstructions, fbtn, fexports]),\n",
    "        )\n",
    "\n",
    "        mainLayout.set_title(1, 'Filtering')\n",
    "        mainLayout.set_title(2, 'Query')\n",
    "       # mainLayout.set_title(3, 'Meta-analysis')\n",
    "        mainLayout.set_title(3, 'Export')\n",
    "        mainLayout.set_title(4, 'Selection')\n",
    "\n",
    "uploadBtn = FileUpload(accept='.xlsx', multiple=False)\n",
    "uploadBtn.observe(loadBtnFunc, names='value')\n",
    "\n",
    "# where to put the url of the Google Sheet\n",
    "gsurl = Text()\n",
    "\n",
    "loadBtn = Button(description='Load File/URL', style= {'button_color':'orange'})\n",
    "loadBtn.on_click(loadBtnFunc)\n",
    "\n",
    "# output for displaying processing\n",
    "out = Output()\n",
    "\n",
    "# case of headers TO KEEP?\n",
    "headerRadio = RadioButtons(\n",
    "    options=['Default (with space)', 'camelCase', 'under_case'],\n",
    "    description=\"Headers:\")\n",
    "\n",
    "mainLayout = Tab([\n",
    "    VBox([Label('Please load the database as .xlsx file.'), \n",
    "          HBox([uploadBtn, Label('OR Google Sheet URL:'), gsurl, loadBtn]),\n",
    "          out])\n",
    "])\n",
    "mainLayout.set_title(0, 'Load Data')\n",
    "\n",
    "display(mainLayout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically start the script if url parameters are provided\n",
    "query_string = os.environ.get('QUERY_STRING', '')\n",
    "parameters = parse_qs(query_string)\n",
    "if 'gsurl' in parameters.keys():\n",
    "    gsurl.value = parameters['gsurl'][0]\n",
    "    loadBtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions:\n",
    "# - shall we include 'Rotation' when merging? some people considered rotation as year so I would go for no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
