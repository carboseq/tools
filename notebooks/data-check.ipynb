{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJP Common template - Data Checking Module\n",
    "Please copy-paste the URL of your completed template or alternatively, upload your filled excel template (.xlsx) and press 'Check' to see if there are any errors that require attention. If there are errors, please make change to the template and check it again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gblanchy\\WPy64-3890\\python-3.8.9.amd64\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\gblanchy\\WPy64-3890\\python-3.8.9.amd64\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\gblanchy\\WPy64-3890\\python-3.8.9.amd64\\lib\\site-packages\\numpy\\.libs\\libopenblas.xwydx2ikjw2nmtwsfyngfuwkqu3lytcz.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from xlsx2csv import Xlsx2csv\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import FileLink, HTML\n",
    "\n",
    "sheetNames = ['experiment', 'reference', 'treatment', 'soil-type', 'tillage', 'crops',\n",
    "              'amendment', 'irrigation', 'pest-weed', 'grazing',\n",
    "             'soil-crop-measurement', 'data', 'dropDownList']\n",
    "\n",
    "def dump(text, level='warning'):\n",
    "    #print(text)\n",
    "    display(HTML('<div class=\"alert alert-{:s}\" role=\"alert\">{:s}</div>'.format(level, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel2(data):\n",
    "    t0 = time.time()\n",
    "    print('Reading in Spreadsheet...', end='')\n",
    "    a = Xlsx2csv(data, outputencoding=\"utf-8\")\n",
    "    dfdic = {}\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        a.convert(td, sheetid=0)\n",
    "        for i, sheet in enumerate(sheetNames):\n",
    "            fname = os.path.join(td, sheet + '.csv')\n",
    "            dfdic[sheet] = pd.read_csv(fname, skiprows=[0,1,3]).dropna(how='all')\n",
    "    datetimeList = [('crops', 'Sowing date'),\n",
    "                    ('crops', 'Harvesting/Termination date'),\n",
    "                    ('tillage', 'Tillage date'),\n",
    "                    ('amendment', 'Amendment date'),\n",
    "                    ('irrigation', 'Irrigation date'),\n",
    "                    ('pest-weed', 'Pesticide application date'),\n",
    "                    ('soil-crop-measurement', 'Sampling date'),\n",
    "                    ('data', 'Date')\n",
    "                   ]\n",
    "    for row in datetimeList:\n",
    "        df = dfdic[row[0]]\n",
    "        df[row[1]] = pd.to_datetime(df[row[1]])\n",
    "    print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "    return dfdic\n",
    "#dfdic = readExcel2('../../../ejp-wp7/ejp-common-template2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel(fname):\n",
    "    if fname[:4] == 'http': # it's a google sheet url\n",
    "        fname = '/'.join(fname.split('/')[:-1] + ['export?format=xlsx'])\n",
    "    dfdic = pd.read_excel(fname, sheet_name=None, skiprows=[0, 1, 3])\n",
    "\n",
    "    # make all ID as string\n",
    "    for key in dfdic:\n",
    "        for dtype in ['Experiment ID', 'Treatment ID']:\n",
    "            if dtype in dfdic[key].columns:\n",
    "                dfdic[key][dtype] = dfdic[key][dtype].astype(str)\n",
    "\n",
    "    # remove Unnamed columns\n",
    "    for key in dfdic.keys():\n",
    "        ie = dfdic[key].columns.str.contains('Unnamed')\n",
    "        dfdic[key] = dfdic[key].drop(dfdic[key].columns[ie], axis=1)\n",
    "\n",
    "    return dfdic\n",
    "\n",
    "#dfdic = readExcel('https://docs.google.com/spreadsheets/d/1aVowuuz5-Ot2RiXViKudeZt9iKHmgkColuXVHWHl_sU/edit?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric types\n",
    "ntypes = {\n",
    "    'experiment': {\n",
    "        'Latitude': 'float',\n",
    "        'Longitude': 'float',\n",
    "    },\n",
    "    'reference': {\n",
    "        'Publication year': 'float',\n",
    "    },\n",
    "    'soil-type': {\n",
    "        'Top depth of layer': 'float',\n",
    "        'Bottom depth of layer': 'float',\n",
    "        'Clay (< 0.002 mm)': 'float',\n",
    "        'Silt (0.002 - 0.05 mm)': 'float',\n",
    "        'Sand (0.05 - 2 mm)': 'float',\n",
    "        'Gravel (> 2 mm)': 'float'\n",
    "    },\n",
    "    'treatment': {\n",
    "        'Year started': 'float',\n",
    "        #'Year ended': 'float'\n",
    "    },\n",
    "    'tillage': {\n",
    "        'Tillage depth': 'float',\n",
    "    },\n",
    "    'crops': {\n",
    "        'Harvesting frequency': 'float',\n",
    "    },\n",
    "    'amendment': {\n",
    "        'Fertilizer/Amendment application rate': 'float',\n",
    "        'Amendment water content': 'float',\n",
    "        'Amendment C': 'float',\n",
    "        'Amendment N': 'float',\n",
    "        'Amendment P': 'float',\n",
    "        'Amendment K': 'float',\n",
    "    },\n",
    "    'irrigation': {\n",
    "        'Amount of water': 'float',\n",
    "        'Irrigation frequency': 'float',\n",
    "        #'Drainage spacing': 'float',\n",
    "        #'Drainage depth': 'float',\n",
    "    },\n",
    "    'data-crop': {\n",
    "        'Sampling year': 'float',\n",
    "        'Harvested yield': 'float',\n",
    "        'Harvested yield water content amount': 'float',\n",
    "        'Residue above-ground': 'float',\n",
    "        'Residue stubble': 'float',\n",
    "        'Residue roots': 'float',\n",
    "        'Below-ground sampling depth': 'float',\n",
    "    },\n",
    "    'data-soil': {\n",
    "        'Sampling year': 'float',\n",
    "        'Depth from': 'float',\n",
    "        'Depth to': 'float',\n",
    "        'SOC conc': 'float',\n",
    "        'SOC conc SD': 'float',\n",
    "        'SOC conc SE': 'float',\n",
    "        'SOC conc nb samples': 'float',\n",
    "        'Bulk density': 'float',\n",
    "        'Bulk density SD': 'float',\n",
    "        'Bulk density SE': 'float',\n",
    "        'Bulk density nb samples': 'float',\n",
    "        'SOC stock': 'float',\n",
    "        'SOC stock SD': 'float',\n",
    "        'SOC stock SE': 'float',\n",
    "        'SOC stock nb samples': 'float',\n",
    "        'pH': 'float',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtype\n",
    "def checkType(dfdic, dic=None):\n",
    "    if dic is None:\n",
    "        dic = {}\n",
    "    wrongTypes = {}\n",
    "    for sheet in ntypes.keys():\n",
    "        for col in ntypes[sheet].keys():\n",
    "            try:\n",
    "                dfdic[sheet][col] = dfdic[sheet][col].astype(ntypes[sheet][col])\n",
    "            except Exception as e:\n",
    "                dump('Wrong type: \"{:s}\" > \"{:s}\" should be float. Error: {:s}'.format(sheet, col, str(e)), 'danger')\n",
    "                if sheet in wrongTypes.keys():\n",
    "                    wrongTypes[sheet].append(col)\n",
    "                else:\n",
    "                    wrongTypes[sheet] = [col]\n",
    "    dic['wrong_types'] = wrongTypes\n",
    "    return dfdic, dic\n",
    "#checkType(dfdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all ID colums contains unique values\n",
    "def checkID(dfdic):\n",
    "    tocheck = [\n",
    "        ('experiment', 'Experiment ID'),\n",
    "        ('treatment', 'Treatment ID'),\n",
    "        ('crops', 'Crop ID'),\n",
    "        ('reference', 'Publication ID')\n",
    "    ]\n",
    "    ok = True\n",
    "#     for a in tocheck:\n",
    "#         df = dfdic[a[0]]\n",
    "#         if len(df[a[1]].unique()) != df.shape[0]:\n",
    "#             dump('{:s} is not unique! ID must be unique.'.format(a[1]), 'danger')\n",
    "#             ok = False\n",
    "    df = dfdic['experiment']\n",
    "    if len(df['Experiment ID'].unique()) != df.shape[0]:\n",
    "        ok = False\n",
    "        dump('Experiment ID are not unique', 'danger')\n",
    "    df = dfdic['treatment']\n",
    "    df['id'] = df['Experiment ID'] + '_' + df['Treatment ID']\n",
    "    ok = True\n",
    "    if len(df['id'].unique()) != df.shape[0]:\n",
    "        dump('Identical Treatment ID for same Experiment ID', 'danger')\n",
    "        ok = False\n",
    "    df = df.drop('id', axis=1)\n",
    "    df = dfdic['crops']\n",
    "    df['id'] = df['Experiment ID'] + '_' + df['Treatment ID'] + '_' + df['Crop ID']\n",
    "    ok = True\n",
    "    if len(df['id'].unique()) != df.shape[0]:\n",
    "        dump('Multiple Crop ID defined for same Treatment ID', 'danger')\n",
    "        ok = False\n",
    "    df = df.drop('id', axis=1)\n",
    "    if ok:\n",
    "        dump('All indexes are unique.', 'success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all Treatment ID are specified in subsequent sheet\n",
    "def checkTreatmentID(dfdic):\n",
    "    experimentIDs = dfdic['experiment']['Experiment ID'].unique()\n",
    "    for expid in experimentIDs:\n",
    "        dftreat = dfdic['treatment']\n",
    "        ie = dftreat['Experiment ID'] == expid\n",
    "        treatmentIDs = dftreat[ie]['Treatment ID'].unique()\n",
    "        tocheck = ['crops', 'pest-weed', 'irrigation', 'tillage']\n",
    "        ok = True\n",
    "        for a in tocheck:\n",
    "            if a in dfdic.keys():\n",
    "                df = dfdic[a]\n",
    "                ie = df['Experiment ID'] == expid\n",
    "                specified = df[ie]['Treatment ID'].values\n",
    "                icommon = np.in1d(treatmentIDs, specified)\n",
    "                if np.sum(~icommon) > 0: # some treatment are not specified\n",
    "                    dump('Treatments \"{:s}\" are not specified in tab \"{:s}\" for Experiment ID \"{:s}\"'.format(\n",
    "                        '\", \"'.join(treatmentIDs[~icommon]), a, expid), 'danger')\n",
    "                    ok = False\n",
    "        if ok:\n",
    "            dump('{:s}: all treatment IDs are specified in the different sheets.'.format(expid), 'success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rotations do not appear suddently (not 100% sure about that)\n",
    "def checkRotation(dfdic):\n",
    "    print('not sure about that...')\n",
    "    rots = dfdic['tillage']['Rotation'].unique()\n",
    "    sheets = ['crops', 'pest-weed', 'irrigation', 'grazing']\n",
    "    for sheet in sheets:\n",
    "        rots2 = dfdic[sheet]['Rotation'].unique()\n",
    "        ie = np.in1d(rots2, rots)\n",
    "        if np.sum(~ie) > 0:\n",
    "            dump('Rotations: {:s} from tab {:s} are not defined in other tabs.'.format(str(rots2[~ie]), sheet), 'danger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check controlled vocabulary and raise new words introduced\n",
    "def checkVocabulary(dfdic):\n",
    "    dfdrop = dfdic['dropDownList']\n",
    "    newWords = {}\n",
    "    for key in dfdic.keys():\n",
    "        df = dfdic[key]\n",
    "        for col in df.columns:\n",
    "            if col in dfdrop.columns:\n",
    "                status = 'ok'\n",
    "                voc = df[col].dropna().unique()\n",
    "                cvoc = dfdrop[col].dropna().values\n",
    "                ie = np.in1d(voc, cvoc)\n",
    "                if np.sum(~ie) > 0:\n",
    "                    status = 'new words: ' + str(voc[~ie]) + 'not in drop-down list'# + str(cvoc)\n",
    "                    newWords[col] = list(voc[~ie])\n",
    "                    dump('check: {:25s} > {:50s}: {:s}'.format(key, col, status), 'warning')\n",
    "                #print('check: {:25s} > {:50s}: {:s}'.format(key, col, status))\n",
    "    if len(newWords) == 0:\n",
    "        dump('All vocabulary used already in drop-down list', 'success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply 'all treatments' to enter it in the relational database\n",
    "def multiplyTreatments(dfdic):\n",
    "    tocheck = ['crops', 'pest-weed', 'irrigation', 'tillage']\n",
    "    dftreat = dfdic['treatment']\n",
    "    dfdic2 = dfdic.copy()\n",
    "    for a in tocheck:\n",
    "        if a in dfdic.keys():\n",
    "            df = dfdic[a]\n",
    "            df2 = pd.DataFrame(columns=df.columns)\n",
    "            for i in range(df.shape[0]):\n",
    "                row = df.loc[i, :].copy()\n",
    "                if row['Treatment ID'] == 'all treatments':\n",
    "                    #print('Sheet \"{:s}\" > experiment \"{:s}\" expanded'.format(\n",
    "                    #a, row['Experiment ID']))\n",
    "                    ie = dftreat['Experiment ID'] == row['Experiment ID']\n",
    "                    treatmentIDs = dftreat[ie]['Treatment ID'].values\n",
    "                    for treatmentID in treatmentIDs:\n",
    "                        row['Treatment ID'] = treatmentID\n",
    "                        df2 = df2.append(row.copy())\n",
    "                else:\n",
    "                    df2 = df2.append(row.copy())\n",
    "            dfdic2[a] = df2.reset_index(drop=True)\n",
    "    return dfdic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify which management practice is treatment specific\n",
    "# TODO for crops, we need to take cropsID into account\n",
    "def extractTreatment(dfdic):\n",
    "    mgnt = ['crops','tillage','amendment','irrigation','pest-weed','grazing']\n",
    "    experimentIDs = dfdic['experiment']['Experiment ID'].unique()\n",
    "    x = np.zeros((len(experimentIDs), len(mgnt)), dtype=bool)\n",
    "    dft = pd.DataFrame(x, columns=mgnt) # True if the practice is part of treatment\n",
    "    dft.insert(0, 'Experiment ID', experimentIDs)\n",
    "    for expid in experimentIDs:\n",
    "        treatList = []\n",
    "        for sheet in mgnt:\n",
    "            if sheet in dfdic.keys():\n",
    "                df = dfdic[sheet]\n",
    "                ie = df['Experiment ID'] == expid\n",
    "                sdf = df[ie].copy().drop(['Experiment ID', 'Treatment ID'], axis=1).reset_index(drop=True)\n",
    "                sdf = sdf.dropna(axis=1)\n",
    "                isTreatment = False\n",
    "                if sdf.shape[0] > 0: # sheet might be empty for expid\n",
    "                    s0 = sdf.loc[0,:]\n",
    "                    for i in range(1, sdf.shape[0]):\n",
    "                        if (sdf.loc[i,:] != s0).any():\n",
    "                            # print('++++++is different:', sdf.loc[i,:], '--', s0, '///', sdf.loc[i,:] != s0)\n",
    "                            isTreatment = True\n",
    "                            break\n",
    "                if isTreatment is True:\n",
    "                    dft.loc[dft['Experiment ID'] == expid, sheet] = True\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unexpected increase in date for sowing or harvesting or for harvesting date after sowing date\n",
    "def checkDates(dfdic):\n",
    "    dfcrop = dfdic['crops']\n",
    "    for i in range(dfcrop.shape[0]):\n",
    "        row = dfcrop.loc[i,:]\n",
    "        sowing = row['Sowing date'].values\n",
    "        harvesting = row['Harvesting/Termination date'].values\n",
    "        if pd.isnull(sowing) and pd.isnull(harvesting):\n",
    "            sowing = row['Sowing period']\n",
    "            harvesting = row['Harvesting/Termination period']\n",
    "            if pd.isnull(sowing) and pd.isnull(harvestig):\n",
    "                print('No sowing date/period AND no harvesting/termination date/period specified for row:', row)\n",
    "        elif not pd.isnull(sowing) and not pd.isnull(harvesting):\n",
    "            if harvesting < sowing:\n",
    "                print('Harvesting/Termination date is smaller than sowing date, please check row {:d} of the \"crops\" tab'.format(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRotation(dfdic, expid):\n",
    "    df = dfdic['crops']\n",
    "    ie1 = df['Experiment ID'] == expid\n",
    "    treatments = df[ie1]['Treatment ID'].unique()\n",
    "    ucrops = df[ie1]['Crop'].unique()\n",
    "    colors = dict(zip(ucrops, [plt.cm.tab10(i) for i in range(len(ucrops))]))\n",
    "    xmax = df[ie1]['Harvesting/Termination date'].max()\n",
    "    fig, ax = plt.subplots(figsize=(14,4))\n",
    "    c = 0\n",
    "    tticks = []\n",
    "    for i, treatment in enumerate(treatments):\n",
    "        ax.axhline(c, color='k', linestyle=':')\n",
    "        tticks.append(c)\n",
    "        c += 1\n",
    "        ie2 = df['Treatment ID'] == treatment\n",
    "        crops = df[ie1 & ie2]['Crop ID'].unique()\n",
    "        for j, crop in enumerate(crops):\n",
    "            ie3 = df['Crop ID'] == crop\n",
    "            row = df[ie1 & ie2 & ie3]\n",
    "            cropName = row['Crop'].values[0]\n",
    "            if 'Sowing date' in row.keys():\n",
    "                sowing = row['Sowing date'].values[0]\n",
    "            elif 'Sowing period' in row.keys():\n",
    "                sowing = datetime.strptime(row['Sowing period'].values[0], '%B')\n",
    "            else:\n",
    "                raise ValueError('No \"Sowing date\" or \"Sowing period\", impossible to do the rotation graph')\n",
    "                return\n",
    "            if 'Harvesting/Termination date' in row.keys():\n",
    "                harvesting = row['Harvesting/Termination date'].values[0]\n",
    "            elif 'Harvesting/Termination period' in row.keys():\n",
    "                harvesting = datetime.strptime(row['Harvesting/Termination period'].values[0], '%B')\n",
    "            if pd.isnull(harvesting):\n",
    "                harvesting = xmax\n",
    "            if not pd.isnull(sowing) and not pd.isnull(harvesting):\n",
    "                xy = np.array([[sowing, c],\n",
    "                              [sowing, c+3],\n",
    "                              [harvesting, c+3],\n",
    "                              [harvesting, c],\n",
    "                              [sowing, c]])\n",
    "                xy[:,0] = mdates.date2num(xy[:,0])\n",
    "                coll = PolyCollection([xy], facecolors=[colors[cropName]], alpha=0.5)\n",
    "                ax.add_collection(coll)\n",
    "                ax.text(sowing + np.abs(sowing - harvesting)/2, c+2,\n",
    "                        cropName.replace('> ','').replace('>',''), ha='center', fontsize=8)\n",
    "                # print(i, j, crop, sowing, harvesting)\n",
    "                # check for overlap to see if we need to skip row?\n",
    "                c += 4\n",
    "    tticks.append(c)\n",
    "    ax.autoscale()\n",
    "    # add vertical bar for year\n",
    "    #xmin, xmax = ax.get_xlim()\n",
    "    #xmin, xmax = mdates.num2date(xmin), mdates.num2date(xmax)\n",
    "    xmin = df[ie1]['Sowing date'].min()\n",
    "    xmin = xmin.replace(month=1, day=1)\n",
    "    xmax = xmax.replace(year=xmax.year+1, month=1, day=1)\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    d = xmin\n",
    "    for i in range(100):\n",
    "        d = d.replace(year=d.year + 1)\n",
    "        if d < xmax:\n",
    "            ax.axvline(d, color='k')\n",
    "    loc = mdates.MonthLocator()\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(loc)) \n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x')\n",
    "    ax.set_yticks(tticks[:-1] + np.diff(tticks)/2)\n",
    "    ax.set_yticklabels(treatments)\n",
    "    fig.autofmt_xdate()\n",
    "    fname = 'rotation-' + str(expid) + '.jpg'\n",
    "    fig.savefig(fname, dpi=500)\n",
    "    plt.show() # needed to plot the graph in the 'out' context\n",
    "    display(FileLink(fname))\n",
    "    \n",
    "#createRotation(dfdic, 'cc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02160047ce954107b25fc9592ebc3e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value={}, description='Upload'), Label(value='OR Google Sheet URL:'), Text(value='',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e7a83f9d2d4110bcb4092171da5c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Check File', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d510db942c346cab4e293dc06edd86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# proof of concept of web-based input file check (on binder for instance)\n",
    "dfdic = pd.DataFrame()\n",
    "upload = widgets.FileUpload()\n",
    "out = widgets.Output()\n",
    "gsurl = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def processBtnFunc(btn):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        #dfdic = readExcel(upload.data[0])\n",
    "        if gsurl.value != '':\n",
    "            dfdic = readExcel(gsurl.value)\n",
    "        elif len(upload.data) > 0:\n",
    "            dfdic = readExcel(upload.data[0])\n",
    "            #with open('t.xlsx', 'wb') as f: # faster but less robust\n",
    "            #    f.write(upload.data[0])\n",
    "            #dfdic = readExcel2('t.xlsx')\n",
    "        else:\n",
    "            raise ValueError('Please upload a .xlsx or specify Google Sheet url')\n",
    "            return\n",
    "        \n",
    "        # drop automatically filled columns with the rest empty\n",
    "        df = dfdic['crops']\n",
    "        dfdic['crops'] = df[df['Crop ID'] != '___'].reset_index(drop=True)\n",
    "        df = dfdic['reference']\n",
    "        dfdic['reference'] = df[df['Publication ID'] != '__'].reset_index(drop=True)\n",
    "\n",
    "        print('\\n\\n--------------------------------- Check IDs ---------------------------------')\n",
    "        checkID(dfdic)\n",
    "        dfdic, _ = checkType(dfdic)\n",
    "        #print('\\n\\n--------------------------------- Expanding Treatment ID --------------------')\n",
    "        dfdic = multiplyTreatments(dfdic)\n",
    "        print('\\n\\n--------------------------------- Check Treatment ID ------------------------')\n",
    "        checkTreatmentID(dfdic)\n",
    "        #print('\\n\\n--------------------------------- Check Rotation ----------------------------')\n",
    "        #checkRotation(dfdic)\n",
    "        print('\\n\\n--------------------------------- Check Controlled Vocabulary ---------------')\n",
    "        checkVocabulary(dfdic)\n",
    "        #print('\\n\\n--------------------------------- Extract Treatments ------------------------')\n",
    "        #dft = extractTreatment(dfdic)\n",
    "        #print(dft)\n",
    "    expDropdown.options = dfdic['experiment']['Experiment ID'].unique()\n",
    "    def rotBtnFunc(a):\n",
    "        with out:\n",
    "            createRotation(dfdic, expDropdown.value)\n",
    "    rotBtn.on_click(rotBtnFunc)\n",
    "processBtn = widgets.Button(description = 'Check File')\n",
    "processBtn.on_click(processBtnFunc)\n",
    "\n",
    "expDropdown = widgets.Dropdown(options=[''], description='')\n",
    "rotBtn = widgets.Button(description='Rotation Graph')\n",
    "\n",
    "# layout\n",
    "display(widgets.HBox([upload, widgets.Label('OR Google Sheet URL:'), gsurl]))\n",
    "display(processBtn)\n",
    "#display(widgets.HBox([widgets.Label('Select experiment for rotation graph:'), expDropdown]))\n",
    "#display(rotBtn)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
