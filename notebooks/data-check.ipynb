{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJP Common template - Data Checking Module\n",
    "Please copy-paste the URL of your completed template or alternatively, upload your filled excel template (.xlsx) and press 'Check' to see if there are any errors that require attention. If there are errors, please make change to the template and check it again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query string parameters: {}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import parse_qs\n",
    "query_string = os.environ.get('QUERY_STRING', '')\n",
    "parameters = parse_qs(query_string)\n",
    "print(\"query string parameters:\", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from xlsx2csv import Xlsx2csv\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import FileLink, HTML\n",
    "\n",
    "sheetNames = ['experiment', 'reference', 'treatment', 'soil-type', 'tillage', 'crops',\n",
    "              'amendment', 'irrigation', 'pest-weed', 'grazing',\n",
    "             'soil-crop-measurement', 'data', 'dropDownList']\n",
    "\n",
    "def dump(text, level='warning'):\n",
    "    #print(text)\n",
    "    display(HTML('<div class=\"alert alert-{:s}\" role=\"alert\">{:s}</div>'.format(level, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readExcel2(data):\n",
    "    t0 = time.time()\n",
    "    print('Reading in Spreadsheet...', end='')\n",
    "    a = Xlsx2csv(data, outputencoding=\"utf-8\")\n",
    "    dfdic = {}\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        a.convert(td, sheetid=0)\n",
    "        for i, sheet in enumerate(sheetNames):\n",
    "            fname = os.path.join(td, sheet + '.csv')\n",
    "            dfdic[sheet] = pd.read_csv(fname, skiprows=[0,1,3]).dropna(how='all')\n",
    "    datetimeList = [('crops', 'Sowing date'),\n",
    "                    ('crops', 'Harvesting/Termination date'),\n",
    "                    ('tillage', 'Tillage date'),\n",
    "                    ('amendment', 'Amendment date'),\n",
    "                    ('irrigation', 'Irrigation date'),\n",
    "                    ('pest-weed', 'Pesticide application date'),\n",
    "                    ('soil-crop-measurement', 'Sampling date'),\n",
    "                    ('data', 'Date')\n",
    "                   ]\n",
    "    for row in datetimeList:\n",
    "        df = dfdic[row[0]]\n",
    "        df[row[1]] = pd.to_datetime(df[row[1]])\n",
    "    print('done ({:.2f}s)'.format(time.time() - t0))\n",
    "    return dfdic\n",
    "#dfdic = readExcel2('../../../ejp-wp7/ejp-common-template2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel(fname):\n",
    "    if fname[:4] == 'http': # it's a google sheet url\n",
    "        fname = '/'.join(fname.split('/')[:-1] + ['export?format=xlsx'])\n",
    "    dfdic = pd.read_excel(fname, sheet_name=None, skiprows=[0, 1, 3])\n",
    "\n",
    "    # remove Unnamed columns\n",
    "    for key in dfdic.keys():\n",
    "        ie = dfdic[key].columns.str.contains('Unnamed')\n",
    "        dfdic[key] = dfdic[key].drop(dfdic[key].columns[ie], axis=1)\n",
    "        dfdic[key] = dfdic[key].dropna(axis=0, how='all').replace(' ', pd.NA).reset_index(drop=True)\n",
    "        if key == 'dropDownList':\n",
    "            dfdic[key] = dfdic[key].rename(columns={'Measurement method': 'Analysis method'})\n",
    "\n",
    "    # make all ID as string\n",
    "    for key in dfdic:\n",
    "        for dtype in ['Experiment ID', 'Treatment ID']:\n",
    "            if dtype in dfdic[key].columns:\n",
    "                dfdic[key][dtype] = dfdic[key][dtype].astype(str)\n",
    "\n",
    "    return dfdic\n",
    "\n",
    "#dfdic = readExcel('../data/ejp7_3-lte-db.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric types\n",
    "ntypes = {\n",
    "    'experiment': {\n",
    "        'Latitude': 'float',\n",
    "        'Longitude': 'float',\n",
    "    },\n",
    "    'reference': {\n",
    "        'Publication year': 'float',\n",
    "    },\n",
    "    'soil-type': {\n",
    "        'Top depth of layer': 'float',\n",
    "        'Bottom depth of layer': 'float',\n",
    "        'Clay (< 0.002 mm)': 'float',\n",
    "        'Silt (0.002 - 0.05 mm)': 'float',\n",
    "        'Sand (0.05 - 2 mm)': 'float',\n",
    "        'Gravel (> 2 mm)': 'float'\n",
    "    },\n",
    "    'treatment': {\n",
    "        'Year started': 'float',\n",
    "        #'Year ended': 'float'\n",
    "    },\n",
    "    'tillage': {\n",
    "        'Tillage depth': 'float',\n",
    "    },\n",
    "    'crops': {\n",
    "        'Harvesting frequency': 'float',\n",
    "    },\n",
    "    'amendment': {\n",
    "        'Fertilizer/Amendment application rate': 'float',\n",
    "        'Amendment water content': 'float',\n",
    "        'Amendment C': 'float',\n",
    "        'Amendment N': 'float',\n",
    "        'Amendment P': 'float',\n",
    "        'Amendment K': 'float',\n",
    "    },\n",
    "    'irrigation': {\n",
    "        'Amount of water': 'float',\n",
    "        'Irrigation frequency': 'float',\n",
    "        #'Drainage spacing': 'float',\n",
    "        #'Drainage depth': 'float',\n",
    "    },\n",
    "    'data-crop': {\n",
    "        'Sampling year': 'float',\n",
    "        'Harvested yield': 'float',\n",
    "        'Harvested yield water content amount': 'float',\n",
    "        'Residue above-ground': 'float',\n",
    "        'Residue stubble': 'float',\n",
    "        'Residue roots': 'float',\n",
    "        'Below-ground sampling depth': 'float',\n",
    "    },\n",
    "    'data-soil': {\n",
    "        'Sampling year': 'float',\n",
    "        'Depth from': 'float',\n",
    "        'Depth to': 'float',\n",
    "        'SOC conc': 'float',\n",
    "        'SOC conc SD': 'float',\n",
    "        'SOC conc SE': 'float',\n",
    "        'SOC conc nb samples': 'float',\n",
    "        'Bulk density': 'float',\n",
    "        'Bulk density SD': 'float',\n",
    "        'Bulk density SE': 'float',\n",
    "        'Bulk density nb samples': 'float',\n",
    "        'SOC stock': 'float',\n",
    "        'SOC stock SD': 'float',\n",
    "        'SOC stock SE': 'float',\n",
    "        'SOC stock nb samples': 'float',\n",
    "        'pH': 'float',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtype\n",
    "def text2num(x):\n",
    "    try:\n",
    "        if type(x) == datetime:\n",
    "            return x.year\n",
    "        else:\n",
    "            return float(x)\n",
    "    except:\n",
    "        try:\n",
    "            return float(str(x).replace(',', '.'))\n",
    "        except:\n",
    "            return x\n",
    "def text2numFix(x):\n",
    "    try:\n",
    "        if type(x) == datetime:\n",
    "            return x.year\n",
    "        else:\n",
    "            return float(x)\n",
    "    except:\n",
    "        try:\n",
    "            return float(str(x).replace(',', '.'))\n",
    "        except:\n",
    "            if (len(str(x).strip()) == 0) | (str(x) == '-'):\n",
    "                return np.nan\n",
    "            else:\n",
    "                try:\n",
    "                    return np.mean([float(a) for a in str(x).split('-')])\n",
    "                except:\n",
    "                    return np.nan\n",
    "\n",
    "def checkType(dfdic, dic=None, fix=False):\n",
    "    if dic is None:\n",
    "        dic = {}\n",
    "    wrongTypes = {}\n",
    "    for sheet in ntypes.keys():\n",
    "        for col in ntypes[sheet].keys():\n",
    "            try:\n",
    "                dfdic[sheet][col] = dfdic[sheet][col].astype(ntypes[sheet][col])\n",
    "            except Exception as e:\n",
    "                # attempt to do automatic conversion\n",
    "                if fix:\n",
    "                    dfdic[sheet][col] = dfdic[sheet][col].apply(text2numFix)\n",
    "                else:\n",
    "                    dfdic[sheet][col] = dfdic[sheet][col].apply(text2num)\n",
    "\n",
    "                # second attempt to convert the entire column\n",
    "                etext = str(e).split(':')[-1]\n",
    "                try:\n",
    "                    dfdic[sheet][col] = dfdic[sheet][col].astype(ntypes[sheet][col])\n",
    "                    if ',' in etext or '-' in etext:\n",
    "                        dump('{:s} > {:s}: Wrong type: {:s} automatically converted to {:s}'.format(\n",
    "                            sheet, col, str(e), str(text2numFix(etext.strip()[1:-1]))), 'info')\n",
    "                except Exception as e:\n",
    "                    dump('{:s} > {:s}: Wrong type: {:s}'.format(sheet, col, str(e)), 'warning')\n",
    "\n",
    "                    # log the columns that couldn't even be converted automatically\n",
    "                    if sheet in wrongTypes.keys():\n",
    "                        wrongTypes[sheet].append(col)\n",
    "                    else:\n",
    "                        wrongTypes[sheet] = [col]\n",
    "    dic['wrong_types'] = wrongTypes\n",
    "    return dfdic\n",
    "#checkType(dfdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all ID colums contains unique values\n",
    "def checkID(dfdic, dic=None, fix=False):\n",
    "    tocheck = [\n",
    "        ('experiment', 'Experiment ID'),\n",
    "        ('treatment', 'Treatment ID'),\n",
    "        ('crops', 'Crop ID'),\n",
    "        ('reference', 'Publication ID')\n",
    "    ]\n",
    "    if dic is None:\n",
    "        dic = {}\n",
    "    ok = True\n",
    "    # check that all rows have all ID specified\n",
    "    dic['missing_id'] = {}\n",
    "    for sheet in sheetNames[:-1]:\n",
    "        if sheet in dfdic.keys():\n",
    "            df = dfdic[sheet]\n",
    "            tdic = {}\n",
    "            for col in ['Experiment ID', 'Treatment ID', 'Crop ID', 'Rotation']:\n",
    "                if col in df.columns:\n",
    "                    nanRow = list(np.where(df[col].values == 'nan')[0] + 5) # so it correspond to excel rows\n",
    "                    if len(nanRow) > 0:\n",
    "                        ok = False\n",
    "                        if fix:\n",
    "                            expids = df[col].values\n",
    "                            a = expids[0]\n",
    "                            for l in range(1, len(expids)):\n",
    "                                if expids[l] == 'nan':\n",
    "                                    expids[l] = a\n",
    "                                else:\n",
    "                                    a = expids[l]\n",
    "                            if np.sum(expids == 'nan') == 0:\n",
    "                                dump('{:s} > {:s}: Missing ID added for rows {:s}'.format(\n",
    "                                sheet, col, ', '.join(list(map(str, nanRow)))), 'info')\n",
    "                                dfdic[sheet].loc[:, col] = expids\n",
    "                            else:\n",
    "                                tdic[col] = list(map(str, nanRow))\n",
    "                                dump('{:s} > {:s}: Missing ID for rows {:s}'.format(\n",
    "                                sheet, col, ', '.join(list(map(str, nanRow)))), 'warning')\n",
    "                        else:\n",
    "                            tdic[col] = list(map(str, nanRow))\n",
    "                            dump('{:s} > {:s}: Missing ID for rows {:s}'.format(\n",
    "                                sheet, col, ', '.join(list(map(str, nanRow)))), 'warning')\n",
    "            if len(tdic.keys()) > 0:\n",
    "                dic[sheet] = tdic\n",
    "\n",
    "    # check Experiment ID\n",
    "    df = dfdic['experiment'].replace('nan', pd.NA)\n",
    "    s_expid = df['Experiment ID'].dropna().value_counts()\n",
    "    if np.sum(s_expid > 1) > 0:\n",
    "        ok = False\n",
    "        dump('experiment > Experiment ID: {:s} are not unique'.format(\n",
    "            str(s_expid[s_expid > 1].index.tolist())), 'danger')\n",
    "        dic['u_expid'] = False\n",
    "    else:\n",
    "        dic['u_expid'] = True\n",
    "\n",
    "    # check Treatment ID\n",
    "    df = dfdic['treatment'].replace('nan', pd.NA)\n",
    "    df['id'] = df['Experiment ID'] + '|||' + df['Treatment ID']\n",
    "    df.loc[df['Treatment ID'].isna(), 'id'] = pd.NA\n",
    "    s_treatid = df['id'].value_counts()\n",
    "    if np.sum(s_treatid > 1) > 0:\n",
    "        ok = False\n",
    "        dic['u_treatid'] = False\n",
    "        for j in np.where(s_treatid > 1)[0]:\n",
    "            expid, treatid = s_treatid.index[j].split('|||')\n",
    "            dump('treatment > Treatment ID: {:s} is not unique for ExpID. {:s}'.format(\n",
    "                treatid, expid), 'danger')\n",
    "    else:\n",
    "        dic['u_treatid'] = True\n",
    "\n",
    "    # check Crop ID\n",
    "    df = df.drop('id', axis=1)\n",
    "    df = dfdic['crops'].replace('nan', pd.NA)\n",
    "    df['id'] = df['Experiment ID'] + '|||' + df['Treatment ID'] + '|||' + df['Crop ID']\n",
    "    df.loc[df['Crop ID'].isna(), 'id'] = pd.NA\n",
    "    s_cropid = df['id'].value_counts()\n",
    "    if np.sum(s_cropid > 1) > 0:\n",
    "        ok = False\n",
    "        dic['u_cropid'] = False\n",
    "        for j in np.where(s_cropid > 1)[0]:\n",
    "            expid, treatid, cropid = s_cropid.index[j].split('|||')\n",
    "            dump('crops > Crop ID: {:s} is not unique for Treatment ID {:s} in Experiment ID {:s}'.format(\n",
    "                 cropid, treatid, expid), 'danger')\n",
    "    else:\n",
    "        dic['u_cropid'] = True\n",
    "    df = df.drop('id', axis=1)\n",
    "    if ok:\n",
    "        dump('All indexes are unique.', 'success')\n",
    "    \n",
    "    return dfdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all Treatment ID are specified in subsequent sheet\n",
    "def checkTreatmentID(dfdic, dic=None, fix=False):\n",
    "    \"\"\"Check that all treatment ID are specified in all sheets.\n",
    "    If ´fix´ is True, then we add empty rows with the missing Treatment ID.\n",
    "    \"\"\"\n",
    "    if dic is None:\n",
    "        dic = {}\n",
    "    dico = {}\n",
    "    experimentIDs = dfdic['experiment']['Experiment ID'].unique()\n",
    "    for expid in experimentIDs:\n",
    "        dic1 = {}\n",
    "        dftreat = dfdic['treatment']\n",
    "        ie = dftreat['Experiment ID'] == expid\n",
    "        treatmentIDs = dftreat[ie]['Treatment ID'].unique()\n",
    "        tocheck = ['tillage', 'crops', 'amendment', 'irrigation', 'pest-weed', 'grazing']\n",
    "        ok = True\n",
    "        for a in tocheck:\n",
    "            if a in dfdic.keys():\n",
    "                df = dfdic[a]\n",
    "                ie = df['Experiment ID'] == expid\n",
    "                specified = df[ie]['Treatment ID'].values\n",
    "                icommon = np.in1d(treatmentIDs, specified)\n",
    "                if np.sum(~icommon) > 0:  # some treatment are not specified\n",
    "                    ok = False\n",
    "                    dic1[a] = list(treatmentIDs[~icommon])\n",
    "                    if fix:\n",
    "                        for t in treatmentIDs[~icommon]:\n",
    "                            dfdic[a] = dfdic[a].append({'Experiment ID': expid, 'Treatment ID': t},\n",
    "                                                        ignore_index=True)\n",
    "                        #dump('{:s} > Treatment IDs \"{:s}\" automatically added for Experiment ID \"{:s}\"'.format(\n",
    "                        #     a, '\", \"'.join(treatmentIDs[~icommon]), expid), 'info')\n",
    "                    else:\n",
    "                        pass\n",
    "                        #dump('{:s} > Treatment IDs \"{:s}\" are not specified for Experiment ID \"{:s}\"'.format(\n",
    "                        #     a, '\", \"'.join(treatmentIDs[~icommon]), expid), 'danger')\n",
    "        dico[expid] = dic1\n",
    "\n",
    "        # additional check for the soil-type tab on expid only (not treatid there)\n",
    "        for expid in experimentIDs:\n",
    "            if expid not in dfdic['soil-type']['Experiment ID'].tolist():\n",
    "                dump('soil-type > Experiment ID \"{:s}\" automatically added but row is empty!'.format(expid), 'info')\n",
    "                if expid not in dico.keys():\n",
    "                    dico[expid] = {'soil-type': []}\n",
    "                else:\n",
    "                    dico[expid].update({'soil-type': []})\n",
    "        if ok:\n",
    "            dump('{:s}: all treatment IDs are specified in the different sheets.'.format(expid), 'success')\n",
    "    dic['s_treatid'] = dico\n",
    "    return dfdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rotations do not appear suddently (not 100% sure about that)\n",
    "def checkRotation(dfdic):\n",
    "    print('not sure about that...')\n",
    "    rots = dfdic['tillage']['Rotation'].unique()\n",
    "    sheets = ['crops', 'pest-weed', 'irrigation', 'grazing']\n",
    "    for sheet in sheets:\n",
    "        rots2 = dfdic[sheet]['Rotation'].unique()\n",
    "        ie = np.in1d(rots2, rots)\n",
    "        if np.sum(~ie) > 0:\n",
    "            dump('Rotations: {:s} from tab {:s} are not defined in other tabs.'.format(str(rots2[~ie]), sheet), 'danger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check controlled vocabulary and raise new words introduced\n",
    "def checkVocabulary(dfdic, dic=None):\n",
    "    if dic is None:\n",
    "        dic = {}\n",
    "    dfdrop = dfdic['dropDownList']\n",
    "    newWords = {}\n",
    "    for key in dfdic.keys():\n",
    "        df = dfdic[key]\n",
    "        for col in df.columns:\n",
    "            if col in dfdrop.columns:\n",
    "                status = 'ok'\n",
    "                voc = df[col].dropna().unique()\n",
    "                cvoc = dfdrop[col].dropna().values\n",
    "                ie = np.in1d(voc, cvoc)\n",
    "                if np.sum(~ie) > 0:\n",
    "                    status = 'new words: ' + \", \".join(voc[~ie]) + ' not in drop-down list'# + str(cvoc)\n",
    "                    newWords[col] = list(voc[~ie])\n",
    "                    dump('{:s} > {:s}: {:s}'.format(key, col, status), 'warning')\n",
    "                #print('check: {:25s} > {:50s}: {:s}'.format(key, col, status))\n",
    "    dic['newWords'] = newWords\n",
    "    if len(newWords) == 0:\n",
    "        dump('All vocabulary used already in drop-down list', 'success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply 'all treatments' to enter it in the relational database\n",
    "def multiplyTreatments(dfdic):\n",
    "    tocheck = ['tillage', 'crops', 'amendment', 'irrigation', 'grazing', 'pest-weed']\n",
    "    dftreat = dfdic['treatment']\n",
    "    dfdic2 = dfdic.copy()\n",
    "    for a in tocheck:\n",
    "        if a in dfdic.keys():\n",
    "            df = dfdic[a]\n",
    "            ie = df['Treatment ID'] == 'all treatments'\n",
    "            df2 = df[~ie].reset_index(drop=True)\n",
    "            toadd = []\n",
    "            for i in np.where(ie)[0]:\n",
    "                row = df.loc[i, :].to_dict()\n",
    "                #print('Sheet \"{:s}\" > experiment \"{:s}\" expanded'.format(\n",
    "                #a, row['Experiment ID']))\n",
    "                ie = dftreat['Experiment ID'] == row['Experiment ID']\n",
    "                treatmentIDs = dftreat[ie]['Treatment ID'].values\n",
    "                for treatmentID in treatmentIDs:\n",
    "                    row['Treatment ID'] = treatmentID\n",
    "                    toadd.append(row.copy())\n",
    "            df2 = df2.append(pd.DataFrame(toadd))\n",
    "            dfdic2[a] = df2.reset_index(drop=True)\n",
    "    return dfdic2\n",
    "\n",
    "#%load_ext line_profiler # run once\n",
    "#dfdic = readExcel(datadir + 'templates/template-n0002.xlsx')\n",
    "#dfdic = multiplyTreatments(dfdic)\n",
    "#%lprun -f multiplyTreatments multiplyTreatments(dfdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unexpected increase in date for sowing or harvesting or for harvesting date after sowing date\n",
    "def checkDates(dfdic):\n",
    "    dfcrop = dfdic['crops']\n",
    "    for i in range(dfcrop.shape[0]):\n",
    "        row = dfcrop.loc[i,:]\n",
    "        sowing = row['Sowing date'].values\n",
    "        harvesting = row['Harvesting/Termination date'].values\n",
    "        if pd.isnull(sowing) and pd.isnull(harvesting):\n",
    "            sowing = row['Sowing period']\n",
    "            harvesting = row['Harvesting/Termination period']\n",
    "            if pd.isnull(sowing) and pd.isnull(harvestig):\n",
    "                print('No sowing date/period AND no harvesting/termination date/period specified for row:', row)\n",
    "        elif not pd.isnull(sowing) and not pd.isnull(harvesting):\n",
    "            if harvesting < sowing:\n",
    "                print('Harvesting/Termination date is smaller than sowing date, please check row {:d} of the \"crops\" tab'.format(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRotation(dfdic, expid):\n",
    "    df = dfdic['crops']\n",
    "    ie1 = df['Experiment ID'] == expid\n",
    "    treatments = df[ie1]['Treatment ID'].unique()\n",
    "    ucrops = df[ie1]['Crop'].unique()\n",
    "    colors = dict(zip(ucrops, [plt.cm.tab10(i) for i in range(len(ucrops))]))\n",
    "    xmax = df[ie1]['Harvesting/Termination date'].max()\n",
    "    fig, ax = plt.subplots(figsize=(14,4))\n",
    "    c = 0\n",
    "    tticks = []\n",
    "    for i, treatment in enumerate(treatments):\n",
    "        ax.axhline(c, color='k', linestyle=':')\n",
    "        tticks.append(c)\n",
    "        c += 1\n",
    "        ie2 = df['Treatment ID'] == treatment\n",
    "        crops = df[ie1 & ie2]['Crop ID'].unique()\n",
    "        for j, crop in enumerate(crops):\n",
    "            ie3 = df['Crop ID'] == crop\n",
    "            row = df[ie1 & ie2 & ie3]\n",
    "            cropName = row['Crop'].values[0]\n",
    "            if 'Sowing date' in row.keys():\n",
    "                sowing = row['Sowing date'].values[0]\n",
    "            elif 'Sowing period' in row.keys():\n",
    "                sowing = datetime.strptime(row['Sowing period'].values[0], '%B')\n",
    "            else:\n",
    "                raise ValueError('No \"Sowing date\" or \"Sowing period\", impossible to do the rotation graph')\n",
    "                return\n",
    "            if 'Harvesting/Termination date' in row.keys():\n",
    "                harvesting = row['Harvesting/Termination date'].values[0]\n",
    "            elif 'Harvesting/Termination period' in row.keys():\n",
    "                harvesting = datetime.strptime(row['Harvesting/Termination period'].values[0], '%B')\n",
    "            if pd.isnull(harvesting):\n",
    "                harvesting = xmax\n",
    "            if not pd.isnull(sowing) and not pd.isnull(harvesting):\n",
    "                xy = np.array([[sowing, c],\n",
    "                              [sowing, c+3],\n",
    "                              [harvesting, c+3],\n",
    "                              [harvesting, c],\n",
    "                              [sowing, c]])\n",
    "                xy[:,0] = mdates.date2num(xy[:,0])\n",
    "                coll = PolyCollection([xy], facecolors=[colors[cropName]], alpha=0.5)\n",
    "                ax.add_collection(coll)\n",
    "                ax.text(sowing + np.abs(sowing - harvesting)/2, c+2,\n",
    "                        cropName.replace('> ','').replace('>',''), ha='center', fontsize=8)\n",
    "                # print(i, j, crop, sowing, harvesting)\n",
    "                # check for overlap to see if we need to skip row?\n",
    "                c += 4\n",
    "    tticks.append(c)\n",
    "    ax.autoscale()\n",
    "    # add vertical bar for year\n",
    "    #xmin, xmax = ax.get_xlim()\n",
    "    #xmin, xmax = mdates.num2date(xmin), mdates.num2date(xmax)\n",
    "    xmin = df[ie1]['Sowing date'].min()\n",
    "    xmin = xmin.replace(month=1, day=1)\n",
    "    xmax = xmax.replace(year=xmax.year+1, month=1, day=1)\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    d = xmin\n",
    "    for i in range(100):\n",
    "        d = d.replace(year=d.year + 1)\n",
    "        if d < xmax:\n",
    "            ax.axvline(d, color='k')\n",
    "    loc = mdates.MonthLocator()\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(loc)) \n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x')\n",
    "    ax.set_yticks(tticks[:-1] + np.diff(tticks)/2)\n",
    "    ax.set_yticklabels(treatments)\n",
    "    fig.autofmt_xdate()\n",
    "    fname = 'rotation-' + str(expid) + '.jpg'\n",
    "    fig.savefig(fname, dpi=500)\n",
    "    plt.show() # needed to plot the graph in the 'out' context\n",
    "    display(FileLink(fname))\n",
    "    \n",
    "#createRotation(dfdic, 'cc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe7289b798341a9931b6d6d71053036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value={}, description='Upload'), Label(value='OR Google Sheet URL:'), Text(value='',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fa0bf6c9c74e7b8ab6cb98f6fb4a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# proof of concept of web-based input file check (on binder for instance)\n",
    "dfdic = pd.DataFrame()\n",
    "upload = widgets.FileUpload()\n",
    "out = widgets.Output()\n",
    "gsurl = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def processBtnFunc(btn):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        #dfdic = readExcel(upload.data[0])\n",
    "        if gsurl.value != '':\n",
    "            dfdic = readExcel(gsurl.value)\n",
    "        elif len(upload.data) > 0:\n",
    "            dfdic = readExcel(upload.data[0])\n",
    "            #with open('t.xlsx', 'wb') as f: # faster but less robust\n",
    "            #    f.write(upload.data[0])\n",
    "            #dfdic = readExcel2('t.xlsx')\n",
    "        else:\n",
    "            raise ValueError('Please upload a .xlsx or specify Google Sheet url')\n",
    "            return\n",
    "\n",
    "        # drop automatically filled columns with the rest empty\n",
    "        df = dfdic['crops']\n",
    "        dfdic['crops'] = df[df['Crop ID'] != '___'].reset_index(drop=True)\n",
    "        df = dfdic['reference']\n",
    "        dfdic['reference'] = df[df['Publication ID'] != '__'].reset_index(drop=True)\n",
    "\n",
    "        print('\\n\\n--------------------------------- Check IDs ---------------------------------')\n",
    "        dfdic = checkID(dfdic, fix=False)\n",
    "        dfdic = checkType(dfdic, fix=False)\n",
    "        #print('\\n\\n--------------------------------- Expanding Treatment ID --------------------')\n",
    "        dfdic = multiplyTreatments(dfdic)\n",
    "        print('\\n\\n--------------------------------- Check Treatment ID ------------------------')\n",
    "        dfdic = checkTreatmentID(dfdic, fix=True)\n",
    "        #print('\\n\\n--------------------------------- Check Rotation ----------------------------')\n",
    "        #checkRotation(dfdic)\n",
    "        print('\\n\\n--------------------------------- Check Controlled Vocabulary ---------------')\n",
    "        checkVocabulary(dfdic)\n",
    "        #print('\\n\\n--------------------------------- Extract Treatments ------------------------')\n",
    "        #dft = extractTreatment(dfdic)\n",
    "        #print(dft)\n",
    "        print('check finished.')\n",
    "    expDropdown.options = dfdic['experiment']['Experiment ID'].unique()\n",
    "    def rotBtnFunc(a):\n",
    "        with out:\n",
    "            createRotation(dfdic, expDropdown.value)\n",
    "    rotBtn.on_click(rotBtnFunc)\n",
    "processBtn = widgets.Button(description = 'Check File', style= {'button_color':'orange'})\n",
    "processBtn.on_click(processBtnFunc)\n",
    "\n",
    "expDropdown = widgets.Dropdown(options=[''], description='')\n",
    "rotBtn = widgets.Button(description='Rotation Graph')\n",
    "\n",
    "# layout\n",
    "display(widgets.HBox([upload, widgets.Label('OR Google Sheet URL:'), gsurl, processBtn]))\n",
    "#display(widgets.HBox([widgets.Label('Select experiment for rotation graph:'), expDropdown]))\n",
    "#display(rotBtn)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
